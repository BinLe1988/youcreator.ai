#!/usr/bin/env python3
"""
AIæ¨¡å‹ä¸‹è½½è„šæœ¬
æ”¯æŒä»Hugging Faceä¸‹è½½å¼€æºæ¨¡å‹
"""

import os
import sys
import argparse
from pathlib import Path
from typing import List, Dict


class ModelDownloader:
    """æ¨¡å‹ä¸‹è½½å™¨"""
    
    def __init__(self, models_dir: str = "./models"):
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(exist_ok=True)
        
        # é¢„å®šä¹‰çš„æ¨¡å‹é…ç½®
        self.available_models = {
            "text": {
                "gpt2": "gpt2",
                "dialogpt": "microsoft/DialoGPT-medium",
                "chatglm": "THUDM/chatglm-6b",
                "llama2-7b": "meta-llama/Llama-2-7b-chat-hf",
                "qwen": "Qwen/Qwen-7B-Chat",
            },
            "image": {
                "sd-1.5": "runwayml/stable-diffusion-v1-5",
                "sd-2.1": "stabilityai/stable-diffusion-2-1",
                "sdxl": "stabilityai/stable-diffusion-xl-base-1.0",
            },
            "music": {
                "musicgen-small": "facebook/musicgen-small",
                "musicgen-medium": "facebook/musicgen-medium",
                "musicgen-large": "facebook/musicgen-large",
            },
            "code": {
                "codegpt": "microsoft/CodeGPT-small-py",
                "codellama-7b": "codellama/CodeLlama-7b-Python-hf",
                "starcoder": "bigcode/starcoder",
            }
        }
    
    def list_models(self, model_type: str = None):
        """åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹"""
        print("ğŸ“‹ å¯ç”¨çš„AIæ¨¡å‹:")
        print("=" * 50)
        
        types_to_show = [model_type] if model_type else self.available_models.keys()
        
        for mtype in types_to_show:
            if mtype in self.available_models:
                print(f"\nğŸ¯ {mtype.upper()} æ¨¡å‹:")
                for name, repo in self.available_models[mtype].items():
                    status = "âœ… å·²ä¸‹è½½" if self._is_downloaded(mtype, name) else "â¬‡ï¸  æœªä¸‹è½½"
                    print(f"  {name:15} | {repo:40} | {status}")
    
    def _is_downloaded(self, model_type: str, model_name: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½"""
        model_path = self.models_dir / model_type / model_name
        return model_path.exists() and any(model_path.iterdir())
    
    def download_model(self, model_type: str, model_name: str, force: bool = False):
        """ä¸‹è½½æŒ‡å®šæ¨¡å‹"""
        if model_type not in self.available_models:
            print(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
            return False
        
        if model_name not in self.available_models[model_type]:
            print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹: {model_name}")
            print(f"å¯ç”¨æ¨¡å‹: {list(self.available_models[model_type].keys())}")
            return False
        
        repo_id = self.available_models[model_type][model_name]
        local_dir = self.models_dir / model_type / model_name
        
        # æ£€æŸ¥æ˜¯å¦å·²ä¸‹è½½
        if self._is_downloaded(model_type, model_name) and not force:
            print(f"âœ… æ¨¡å‹ {model_name} å·²å­˜åœ¨ï¼Œä½¿ç”¨ --force å¼ºåˆ¶é‡æ–°ä¸‹è½½")
            return True
        
        print(f"ğŸš€ å¼€å§‹ä¸‹è½½ {model_type} æ¨¡å‹: {model_name}")
        print(f"ğŸ“¦ ä»“åº“: {repo_id}")
        print(f"ğŸ“ æœ¬åœ°è·¯å¾„: {local_dir}")
        
        try:
            # åˆ›å»ºç›®å½•
            local_dir.mkdir(parents=True, exist_ok=True)
            
            # ä½¿ç”¨huggingface_hubä¸‹è½½
            from huggingface_hub import snapshot_download
            
            snapshot_download(
                repo_id=repo_id,
                local_dir=str(local_dir),
                local_dir_use_symlinks=False,
                resume_download=True
            )
            
            print(f"âœ… æ¨¡å‹ {model_name} ä¸‹è½½å®Œæˆ!")
            return True
            
        except ImportError:
            print("âŒ è¯·å…ˆå®‰è£… huggingface_hub:")
            print("pip install huggingface_hub")
            return False
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def download_recommended_set(self):
        """ä¸‹è½½æ¨èçš„æ¨¡å‹ç»„åˆ"""
        print("ğŸ¯ ä¸‹è½½æ¨èæ¨¡å‹ç»„åˆ...")
        
        recommended = [
            ("text", "dialogpt"),      # è½»é‡çº§æ–‡æœ¬æ¨¡å‹
            ("image", "sd-1.5"),       # ç»å…¸å›¾åƒæ¨¡å‹
            ("music", "musicgen-small"), # å°å‹éŸ³ä¹æ¨¡å‹
            ("code", "codegpt"),       # ä»£ç ç”Ÿæˆæ¨¡å‹
        ]
        
        success_count = 0
        for model_type, model_name in recommended:
            if self.download_model(model_type, model_name):
                success_count += 1
        
        print(f"\nğŸ‰ æ¨èæ¨¡å‹ä¸‹è½½å®Œæˆ: {success_count}/{len(recommended)}")
    
    def check_requirements(self):
        """æ£€æŸ¥ç³»ç»Ÿè¦æ±‚"""
        print("ğŸ” æ£€æŸ¥ç³»ç»Ÿè¦æ±‚...")
        
        # æ£€æŸ¥PythonåŒ…
        required_packages = [
            "torch", "transformers", "diffusers", 
            "huggingface_hub", "accelerate"
        ]
        
        missing_packages = []
        for package in required_packages:
            try:
                __import__(package)
                print(f"âœ… {package}")
            except ImportError:
                print(f"âŒ {package} (æœªå®‰è£…)")
                missing_packages.append(package)
        
        if missing_packages:
            print(f"\nğŸ“¦ è¯·å®‰è£…ç¼ºå¤±çš„åŒ…:")
            print(f"pip install {' '.join(missing_packages)}")
            return False
        
        # æ£€æŸ¥GPU
        try:
            import torch
            if torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
                print(f"ğŸ® GPU: {gpu_name} ({gpu_memory:.1f}GB)")
                print(f"ğŸ”¢ GPUæ•°é‡: {gpu_count}")
            else:
                print("âš ï¸  æœªæ£€æµ‹åˆ°CUDA GPUï¼Œå°†ä½¿ç”¨CPU (é€Ÿåº¦è¾ƒæ…¢)")
        except:
            print("âŒ æ— æ³•æ£€æµ‹GPUçŠ¶æ€")
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        import shutil
        free_space = shutil.disk_usage(self.models_dir).free / 1e9
        print(f"ğŸ’¾ å¯ç”¨ç£ç›˜ç©ºé—´: {free_space:.1f}GB")
        
        if free_space < 50:
            print("âš ï¸  ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œå»ºè®®è‡³å°‘50GBç”¨äºå­˜å‚¨æ¨¡å‹")
        
        return len(missing_packages) == 0


def main():
    parser = argparse.ArgumentParser(description="YouCreator.AI æ¨¡å‹ä¸‹è½½å·¥å…·")
    parser.add_argument("--models-dir", default="./models", help="æ¨¡å‹å­˜å‚¨ç›®å½•")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºå¯ç”¨æ¨¡å‹")
    parser.add_argument("--type", choices=["text", "image", "music", "code"], help="æ¨¡å‹ç±»å‹")
    parser.add_argument("--download", help="ä¸‹è½½æŒ‡å®šæ¨¡å‹")
    parser.add_argument("--recommended", action="store_true", help="ä¸‹è½½æ¨èæ¨¡å‹ç»„åˆ")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶é‡æ–°ä¸‹è½½")
    parser.add_argument("--check", action="store_true", help="æ£€æŸ¥ç³»ç»Ÿè¦æ±‚")
    
    args = parser.parse_args()
    
    downloader = ModelDownloader(args.models_dir)
    
    if args.check:
        downloader.check_requirements()
    elif args.list:
        downloader.list_models(args.type)
    elif args.recommended:
        if downloader.check_requirements():
            downloader.download_recommended_set()
    elif args.download:
        if not args.type:
            print("âŒ è¯·æŒ‡å®šæ¨¡å‹ç±»å‹ --type")
            sys.exit(1)
        downloader.download_model(args.type, args.download, args.force)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
