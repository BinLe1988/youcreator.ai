#!/usr/bin/env python3
"""
å¼€æºæ¨¡å‹ä¸‹è½½è„šæœ¬
ä¸“é—¨ä¸ºYouCreator.AIä¸‹è½½å’Œé…ç½®å¼€æºæ¨¡å‹
"""

import os
import sys
from pathlib import Path
import subprocess
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class OpenSourceModelDownloader:
    """å¼€æºæ¨¡å‹ä¸‹è½½å™¨"""
    
    def __init__(self):
        self.models_dir = Path("./models")
        self.models_dir.mkdir(exist_ok=True)
        
        # æ¨èçš„å¼€æºæ¨¡å‹é…ç½®
        self.recommended_models = {
            "text": {
                "name": "Qwen2-1.5B-Instruct",
                "repo": "Qwen/Qwen2-1.5B-Instruct",
                "size": "~3GB",
                "description": "é˜¿é‡Œäº‘å¼€æºçš„è½»é‡çº§ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹"
            },
            "image": {
                "name": "Stable Diffusion v1.5",
                "repo": "runwayml/stable-diffusion-v1-5",
                "size": "~4GB", 
                "description": "ç»å…¸çš„å¼€æºå›¾åƒç”Ÿæˆæ¨¡å‹"
            },
            "code": {
                "name": "CodeGPT-small-py",
                "repo": "microsoft/CodeGPT-small-py",
                "size": "~500MB",
                "description": "å¾®è½¯å¼€æºçš„Pythonä»£ç ç”Ÿæˆæ¨¡å‹"
            }
        }
    
    def check_requirements(self):
        """æ£€æŸ¥ç³»ç»Ÿè¦æ±‚"""
        logger.info("ğŸ” æ£€æŸ¥ç³»ç»Ÿè¦æ±‚...")
        
        # æ£€æŸ¥PythonåŒ…
        required_packages = {
            "torch": "PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶",
            "transformers": "Hugging Face Transformers",
            "diffusers": "Hugging Face Diffusers",
            "huggingface_hub": "Hugging Face Hubå®¢æˆ·ç«¯"
        }
        
        missing_packages = []
        for package, description in required_packages.items():
            try:
                __import__(package)
                logger.info(f"âœ… {package} - {description}")
            except ImportError:
                logger.warning(f"âŒ {package} - {description} (æœªå®‰è£…)")
                missing_packages.append(package)
        
        if missing_packages:
            logger.error("âŒ ç¼ºå°‘å¿…è¦çš„PythonåŒ…")
            logger.info("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
            logger.info(f"pip install {' '.join(missing_packages)}")
            return False
        
        # æ£€æŸ¥GPU
        try:
            import torch
            if torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
                logger.info(f"ğŸ® GPU: {gpu_name} ({gpu_memory:.1f}GB)")
                
                if gpu_memory < 4:
                    logger.warning("âš ï¸ GPUå†…å­˜ä¸è¶³4GBï¼Œå»ºè®®ä½¿ç”¨CPUç‰ˆæœ¬æˆ–å‡çº§GPU")
            else:
                logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°CUDA GPUï¼Œå°†ä½¿ç”¨CPUè¿è¡Œ (é€Ÿåº¦è¾ƒæ…¢)")
        except Exception as e:
            logger.error(f"âŒ GPUæ£€æµ‹å¤±è´¥: {e}")
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        import shutil
        free_space = shutil.disk_usage(self.models_dir).free / 1e9
        logger.info(f"ğŸ’¾ å¯ç”¨ç£ç›˜ç©ºé—´: {free_space:.1f}GB")
        
        if free_space < 20:
            logger.warning("âš ï¸ ç£ç›˜ç©ºé—´ä¸è¶³20GBï¼Œå¯èƒ½æ— æ³•ä¸‹è½½æ‰€æœ‰æ¨¡å‹")
        
        return len(missing_packages) == 0
    
    def install_dependencies(self):
        """å®‰è£…å¿…è¦çš„ä¾èµ–"""
        logger.info("ğŸ“¦ å®‰è£…AIæ¨¡å‹ä¾èµ–...")
        
        dependencies = [
            "torch>=2.0.0",
            "transformers>=4.30.0", 
            "diffusers>=0.20.0",
            "accelerate>=0.20.0",
            "huggingface_hub>=0.16.0",
            "safetensors>=0.3.0"
        ]
        
        try:
            subprocess.check_call([
                sys.executable, "-m", "pip", "install", "--upgrade"
            ] + dependencies)
            logger.info("âœ… ä¾èµ–å®‰è£…å®Œæˆ")
            return True
        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ ä¾èµ–å®‰è£…å¤±è´¥: {e}")
            return False
    
    def download_model(self, model_type: str, force: bool = False):
        """ä¸‹è½½æŒ‡å®šç±»å‹çš„æ¨¡å‹"""
        if model_type not in self.recommended_models:
            logger.error(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
            return False
        
        model_info = self.recommended_models[model_type]
        local_dir = self.models_dir / model_type / model_info["name"].lower().replace("-", "_")
        
        # æ£€æŸ¥æ˜¯å¦å·²ä¸‹è½½
        if local_dir.exists() and any(local_dir.iterdir()) and not force:
            logger.info(f"âœ… æ¨¡å‹ {model_info['name']} å·²å­˜åœ¨")
            return True
        
        logger.info(f"ğŸš€ ä¸‹è½½ {model_type} æ¨¡å‹: {model_info['name']}")
        logger.info(f"ğŸ“¦ ä»“åº“: {model_info['repo']}")
        logger.info(f"ğŸ“ å¤§å°: {model_info['size']}")
        logger.info(f"ğŸ“ æè¿°: {model_info['description']}")
        logger.info(f"ğŸ“ æœ¬åœ°è·¯å¾„: {local_dir}")
        
        try:
            # åˆ›å»ºç›®å½•
            local_dir.mkdir(parents=True, exist_ok=True)
            
            # ä½¿ç”¨huggingface_hubä¸‹è½½
            from huggingface_hub import snapshot_download
            
            logger.info("â¬‡ï¸ å¼€å§‹ä¸‹è½½...")
            snapshot_download(
                repo_id=model_info["repo"],
                local_dir=str(local_dir),
                local_dir_use_symlinks=False,
                resume_download=True,
                ignore_patterns=["*.bin"] if model_type == "image" else None  # å›¾åƒæ¨¡å‹ä¼˜å…ˆä¸‹è½½safetensors
            )
            
            logger.info(f"âœ… æ¨¡å‹ {model_info['name']} ä¸‹è½½å®Œæˆ!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def download_all_models(self, force: bool = False):
        """ä¸‹è½½æ‰€æœ‰æ¨èæ¨¡å‹"""
        logger.info("ğŸ¯ ä¸‹è½½æ‰€æœ‰æ¨èçš„å¼€æºæ¨¡å‹...")
        
        success_count = 0
        total_count = len(self.recommended_models)
        
        for model_type in self.recommended_models:
            if self.download_model(model_type, force):
                success_count += 1
            else:
                logger.warning(f"âš ï¸ {model_type} æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè·³è¿‡...")
        
        logger.info(f"ğŸ‰ æ¨¡å‹ä¸‹è½½å®Œæˆ: {success_count}/{total_count}")
        
        if success_count > 0:
            self.create_model_config()
        
        return success_count == total_count
    
    def create_model_config(self):
        """åˆ›å»ºæ¨¡å‹é…ç½®æ–‡ä»¶"""
        logger.info("âš™ï¸ åˆ›å»ºæ¨¡å‹é…ç½®...")
        
        config_content = """# å¼€æºæ¨¡å‹é…ç½®å·²ç”Ÿæˆ
# æ¨¡å‹å·²ä¸‹è½½åˆ° ./models/ ç›®å½•

# æ–‡æœ¬æ¨¡å‹
TEXT_MODEL_PROVIDER=local
TEXT_MODEL_PATH=./models/text/qwen2_1_5b_instruct
TEXT_MODEL_ID=Qwen/Qwen2-1.5B-Instruct

# å›¾åƒæ¨¡å‹  
IMAGE_MODEL_PROVIDER=local
IMAGE_MODEL_PATH=./models/image/stable_diffusion_v1_5
IMAGE_MODEL_ID=runwayml/stable-diffusion-v1-5

# ä»£ç æ¨¡å‹
CODE_MODEL_PROVIDER=local
CODE_MODEL_PATH=./models/code/codegpt_small_py
CODE_MODEL_ID=microsoft/CodeGPT-small-py

# éŸ³ä¹æ¨¡å‹ (æš‚æœªä¸‹è½½)
MUSIC_MODEL_PROVIDER=local
MUSIC_MODEL_PATH=./models/music/musicgen_small
MUSIC_MODEL_ID=facebook/musicgen-small
"""
        
        with open(".env.models", "w", encoding="utf-8") as f:
            f.write(config_content)
        
        logger.info("âœ… æ¨¡å‹é…ç½®æ–‡ä»¶å·²åˆ›å»º: .env.models")
    
    def list_models(self):
        """åˆ—å‡ºæ¨èçš„æ¨¡å‹"""
        logger.info("ğŸ“‹ æ¨èçš„å¼€æºæ¨¡å‹:")
        logger.info("=" * 60)
        
        for model_type, info in self.recommended_models.items():
            local_dir = self.models_dir / model_type / info["name"].lower().replace("-", "_")
            status = "âœ… å·²ä¸‹è½½" if (local_dir.exists() and any(local_dir.iterdir())) else "â¬‡ï¸ æœªä¸‹è½½"
            
            logger.info(f"\nğŸ¯ {model_type.upper()} æ¨¡å‹:")
            logger.info(f"  åç§°: {info['name']}")
            logger.info(f"  ä»“åº“: {info['repo']}")
            logger.info(f"  å¤§å°: {info['size']}")
            logger.info(f"  çŠ¶æ€: {status}")
            logger.info(f"  æè¿°: {info['description']}")
    
    def get_download_commands(self):
        """è·å–ä¸‹è½½å‘½ä»¤"""
        logger.info("ğŸ“‹ æ‰‹åŠ¨ä¸‹è½½å‘½ä»¤:")
        logger.info("=" * 50)
        
        for model_type, info in self.recommended_models.items():
            logger.info(f"\n# ä¸‹è½½ {model_type} æ¨¡å‹")
            logger.info(f"python download_opensource_models.py --type {model_type}")
        
        logger.info(f"\n# ä¸‹è½½æ‰€æœ‰æ¨¡å‹")
        logger.info(f"python download_opensource_models.py --all")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="YouCreator.AI å¼€æºæ¨¡å‹ä¸‹è½½å·¥å…·")
    parser.add_argument("--check", action="store_true", help="æ£€æŸ¥ç³»ç»Ÿè¦æ±‚")
    parser.add_argument("--install-deps", action="store_true", help="å®‰è£…ä¾èµ–")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºæ¨èæ¨¡å‹")
    parser.add_argument("--type", choices=["text", "image", "code"], help="ä¸‹è½½æŒ‡å®šç±»å‹æ¨¡å‹")
    parser.add_argument("--all", action="store_true", help="ä¸‹è½½æ‰€æœ‰æ¨èæ¨¡å‹")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶é‡æ–°ä¸‹è½½")
    parser.add_argument("--commands", action="store_true", help="æ˜¾ç¤ºä¸‹è½½å‘½ä»¤")
    
    args = parser.parse_args()
    
    downloader = OpenSourceModelDownloader()
    
    if args.check:
        downloader.check_requirements()
    elif args.install_deps:
        downloader.install_dependencies()
    elif args.list:
        downloader.list_models()
    elif args.commands:
        downloader.get_download_commands()
    elif args.type:
        if downloader.check_requirements():
            downloader.download_model(args.type, args.force)
    elif args.all:
        if downloader.check_requirements():
            downloader.download_all_models(args.force)
    else:
        # é»˜è®¤æµç¨‹
        logger.info("ğŸ‰ æ¬¢è¿ä½¿ç”¨ YouCreator.AI å¼€æºæ¨¡å‹ä¸‹è½½å·¥å…·!")
        logger.info("=" * 50)
        
        # æ£€æŸ¥è¦æ±‚
        if not downloader.check_requirements():
            logger.info("\nğŸ“¦ æ­£åœ¨å®‰è£…å¿…è¦ä¾èµ–...")
            if downloader.install_dependencies():
                logger.info("âœ… ä¾èµ–å®‰è£…å®Œæˆï¼Œè¯·é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
            return
        
        # åˆ—å‡ºæ¨¡å‹
        downloader.list_models()
        
        # è¯¢é—®æ˜¯å¦ä¸‹è½½
        response = input("\næ˜¯å¦ä¸‹è½½æ‰€æœ‰æ¨èæ¨¡å‹? (y/n): ").strip().lower()
        if response == 'y':
            downloader.download_all_models()
        else:
            downloader.get_download_commands()


if __name__ == "__main__":
    main()
