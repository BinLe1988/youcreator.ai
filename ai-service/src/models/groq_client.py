"""
Groq APIå®¢æˆ·ç«¯
æä¾›å…è´¹çš„é«˜é€ŸLLaMAæ¨¡å‹è®¿é—®
"""

import os
import httpx
import asyncio
import logging
from typing import Dict, Any, Optional
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

logger = logging.getLogger(__name__)


class GroqClient:
    """Groq APIå®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.api_key = os.getenv("GROQ_API_KEY")
        # ä½¿ç”¨æ ‡å‡†çš„OpenAIå…¼å®¹ç«¯ç‚¹
        self.base_url = "https://api.groq.com/openai/v1"
        self.text_model = os.getenv("GROQ_MODEL_TEXT", "llama3-8b-8192")
        self.code_model = os.getenv("GROQ_MODEL_CODE", "llama3-8b-8192")
        
        if not self.api_key:
            logger.warning("âš ï¸ Groq APIå¯†é’¥æœªé…ç½®")
            self.enabled = False
        else:
            self.enabled = True
            logger.info(f"âœ… Groqå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨æ¨¡å‹: {self.text_model}")
            logger.info(f"ğŸ”‘ APIå¯†é’¥: {self.api_key[:20]}...")
    
    async def generate_text(self, prompt: str, **kwargs) -> str:
        """ä½¿ç”¨Groqç”Ÿæˆæ–‡æœ¬"""
        if not self.enabled:
            return self._generate_fallback_text(prompt, **kwargs)
        
        try:
            max_tokens = min(kwargs.get("max_tokens", 1000), 4000)
            temperature = kwargs.get("temperature", 0.7)
            
            # ä½¿ç”¨å®˜æ–¹æ¨èçš„Groq Pythonå®¢æˆ·ç«¯æ ¼å¼
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
                "User-Agent": "YouCreator.AI/1.0"
            }
            
            # å°è¯•ä¸åŒçš„æ¨¡å‹åç§°
            models_to_try = [
                "llama3-8b-8192",
                "llama-3.1-8b-instant", 
                "mixtral-8x7b-32768",
                "gemma-7b-it"
            ]
            
            for model in models_to_try:
                data = {
                    "model": model,
                    "messages": [
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "max_tokens": max_tokens,
                    "temperature": temperature,
                    "stream": False
                }
                
                logger.info(f"ğŸš€ å°è¯•Groqæ¨¡å‹ {model}: {prompt[:50]}...")
                
                try:
                    async with httpx.AsyncClient(timeout=30.0) as client:
                        response = await client.post(
                            f"{self.base_url}/chat/completions",
                            headers=headers,
                            json=data
                        )
                        
                        if response.status_code == 200:
                            result = response.json()
                            generated_text = result["choices"][0]["message"]["content"]
                            logger.info(f"âœ… Groqæ–‡æœ¬ç”ŸæˆæˆåŠŸ ({model})ï¼Œé•¿åº¦: {len(generated_text)}")
                            return generated_text
                        elif response.status_code == 401:
                            logger.error("âŒ Groq APIå¯†é’¥æ— æ•ˆ")
                            break
                        elif response.status_code == 404:
                            logger.warning(f"âš ï¸ æ¨¡å‹ {model} ä¸å¯ç”¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
                            continue
                        else:
                            logger.warning(f"âš ï¸ Groq APIè¿”å› {response.status_code}: {response.text[:100]}")
                            continue
                            
                except Exception as e:
                    logger.warning(f"âš ï¸ æ¨¡å‹ {model} è¯·æ±‚å¤±è´¥: {e}")
                    continue
            
            # å¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
            logger.warning("âš ï¸ æ‰€æœ‰Groqæ¨¡å‹éƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
            return self._generate_fallback_text(prompt, **kwargs)
                    
        except Exception as e:
            logger.error(f"âŒ Groqæ–‡æœ¬ç”Ÿæˆå¤±è´¥: {e}")
            return self._generate_fallback_text(prompt, **kwargs)
    
    async def generate_code(self, prompt: str, **kwargs) -> str:
        """ä½¿ç”¨Groqç”Ÿæˆä»£ç """
        if not self.enabled:
            return self._generate_enhanced_code_template(prompt, kwargs.get("language", "python"))
        
        try:
            language = kwargs.get("language", "python")
            max_tokens = min(kwargs.get("max_tokens", 1000), 4000)
            
            # æ„å»ºä»£ç ç”Ÿæˆæç¤º
            code_prompt = f"""è¯·ç”¨{language}ç¼–å†™ä»£ç æ¥å®ç°ä»¥ä¸‹éœ€æ±‚ï¼š

{prompt}

è¯·åªè¿”å›ä»£ç ï¼Œä¸è¦åŒ…å«è§£é‡Šæ–‡å­—ã€‚"""
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
                "User-Agent": "YouCreator.AI/1.0"
            }
            
            # å°è¯•ä¸åŒçš„æ¨¡å‹
            models_to_try = [
                "llama3-8b-8192",
                "llama-3.1-8b-instant",
                "mixtral-8x7b-32768"
            ]
            
            for model in models_to_try:
                data = {
                    "model": model,
                    "messages": [
                        {
                            "role": "system",
                            "content": f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{language}ç¨‹åºå‘˜ï¼Œåªè¿”å›é«˜è´¨é‡çš„ä»£ç ï¼Œä¸åŒ…å«è§£é‡Šã€‚"
                        },
                        {
                            "role": "user",
                            "content": code_prompt
                        }
                    ],
                    "max_tokens": max_tokens,
                    "temperature": 0.2,
                    "stream": False
                }
                
                logger.info(f"ğŸš€ å°è¯•Groqä»£ç ç”Ÿæˆ {model}: {prompt[:50]}...")
                
                try:
                    async with httpx.AsyncClient(timeout=30.0) as client:
                        response = await client.post(
                            f"{self.base_url}/chat/completions",
                            headers=headers,
                            json=data
                        )
                        
                        if response.status_code == 200:
                            result = response.json()
                            generated_code = result["choices"][0]["message"]["content"]
                            logger.info(f"âœ… Groqä»£ç ç”ŸæˆæˆåŠŸ ({model})ï¼Œé•¿åº¦: {len(generated_code)}")
                            return generated_code
                        elif response.status_code == 401:
                            logger.error("âŒ Groq APIå¯†é’¥æ— æ•ˆ")
                            break
                        elif response.status_code == 404:
                            logger.warning(f"âš ï¸ æ¨¡å‹ {model} ä¸å¯ç”¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
                            continue
                        else:
                            logger.warning(f"âš ï¸ Groq APIè¿”å› {response.status_code}")
                            continue
                            
                except Exception as e:
                    logger.warning(f"âš ï¸ æ¨¡å‹ {model} è¯·æ±‚å¤±è´¥: {e}")
                    continue
            
            # å¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
            logger.warning("âš ï¸ æ‰€æœ‰Groqæ¨¡å‹éƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
            return self._generate_enhanced_code_template(prompt, language)
                    
        except Exception as e:
            logger.error(f"âŒ Groqä»£ç ç”Ÿæˆå¤±è´¥: {e}")
            return self._generate_enhanced_code_template(prompt, language)
    
    def _generate_fallback_text(self, prompt: str, **kwargs) -> str:
        """å¤‡ç”¨æ–‡æœ¬ç”Ÿæˆ"""
        sample_responses = [
            f"åŸºäºæ‚¨çš„æç¤ºã€Œ{prompt}ã€ï¼Œè¿™é‡Œæ˜¯AIç”Ÿæˆçš„åˆ›æ„å†…å®¹ã€‚åœ¨è¿™ä¸ªå……æ»¡æƒ³è±¡åŠ›çš„ä¸–ç•Œé‡Œï¼Œæ¯ä¸€ä¸ªæƒ³æ³•éƒ½èƒ½å¤Ÿè½¬åŒ–ä¸ºç²¾å½©çš„æ•…äº‹ã€‚äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬åˆ›ä½œçš„æ–¹å¼ï¼Œè®©æ¯ä¸ªäººéƒ½èƒ½æˆä¸ºä¼˜ç§€çš„åˆ›ä½œè€…ã€‚é€šè¿‡ä¸æ–­çš„å­¦ä¹ å’Œä¼˜åŒ–ï¼ŒAIèƒ½å¤Ÿç†è§£äººç±»çš„åˆ›æ„éœ€æ±‚ï¼Œå¹¶æä¾›æœ‰ä»·å€¼çš„åˆ›ä½œå»ºè®®ã€‚",
            
            f"å…³äºã€Œ{prompt}ã€çš„æ€è€ƒï¼šåœ¨æ•°å­—åŒ–æ—¶ä»£ï¼Œåˆ›æ„ä¸æŠ€æœ¯çš„ç»“åˆä¸ºæˆ‘ä»¬æ‰“å¼€äº†æ— é™å¯èƒ½çš„å¤§é—¨ã€‚AIä¸ä»…æ˜¯å·¥å…·ï¼Œæ›´æ˜¯åˆ›ä½œçš„ä¼™ä¼´ï¼Œå¸®åŠ©æˆ‘ä»¬æ¢ç´¢å‰æ‰€æœªæœ‰çš„åˆ›æ„é¢†åŸŸã€‚æ¯ä¸€æ¬¡çš„åˆ›ä½œéƒ½æ˜¯ä¸€æ¬¡æ–°çš„æ¢ç´¢ï¼Œæ¯ä¸€ä¸ªæƒ³æ³•éƒ½å¯èƒ½æˆä¸ºä¸‹ä¸€ä¸ªä¼Ÿå¤§ä½œå“çš„èµ·ç‚¹ã€‚",
            
            f"çµæ„Ÿæ¥æºäºã€Œ{prompt}ã€ï¼šåˆ›ä½œæ˜¯äººç±»æœ€ç‹¬ç‰¹çš„èƒ½åŠ›ä¹‹ä¸€ï¼Œè€ŒAIçš„åŠ å…¥è®©è¿™ç§èƒ½åŠ›å¾—åˆ°äº†å‰æ‰€æœªæœ‰çš„å¢å¼ºã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸ä»…åœ¨åˆ›é€ å†…å®¹ï¼Œæ›´åœ¨åˆ›é€ å¯èƒ½æ€§ã€‚è®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢è¿™ä¸ªå……æ»¡åˆ›æ„å’Œæƒ³è±¡åŠ›çš„æ–°ä¸–ç•Œï¼Œç”¨æŠ€æœ¯çš„åŠ›é‡é‡Šæ”¾äººç±»çš„åˆ›é€ æ½œèƒ½ã€‚"
        ]
        
        import random
        return random.choice(sample_responses)
    
    def _generate_enhanced_code_template(self, prompt: str, language: str) -> str:
        """ç”Ÿæˆå¢å¼ºçš„ä»£ç æ¨¡æ¿"""
        if "æ–æ³¢é‚£å¥‘" in prompt or "fibonacci" in prompt.lower():
            if language == "python":
                return '''def fibonacci(n):
    """
    è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬né¡¹
    ä½¿ç”¨é€’å½’æ–¹æ³•ï¼ˆé€‚åˆå°æ•°å€¼ï¼‰
    """
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

def fibonacci_optimized(n):
    """
    è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬né¡¹
    ä½¿ç”¨åŠ¨æ€è§„åˆ’ä¼˜åŒ–ï¼ˆæ¨èï¼‰
    """
    if n <= 1:
        return n
    
    a, b = 0, 1
    for _ in range(2, n + 1):
        a, b = b, a + b
    return b

def fibonacci_sequence(count):
    """
    ç”Ÿæˆæ–æ³¢é‚£å¥‘æ•°åˆ—çš„å‰counté¡¹
    """
    sequence = []
    for i in range(count):
        sequence.append(fibonacci_optimized(i))
    return sequence

# æµ‹è¯•å’Œæ¼”ç¤º
if __name__ == "__main__":
    print("æ–æ³¢é‚£å¥‘æ•°åˆ—æ¼”ç¤º:")
    print(f"F(10) = {fibonacci_optimized(10)}")
    print(f"å‰15é¡¹: {fibonacci_sequence(15)}")'''
        
        # å…¶ä»–å¸¸è§ç®—æ³•æ¨¡æ¿
        if "æ’åº" in prompt or "sort" in prompt.lower():
            if language == "python":
                return '''def bubble_sort(arr):
    """
    å†’æ³¡æ’åºç®—æ³•
    """
    n = len(arr)
    for i in range(n):
        for j in range(0, n-i-1):
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]
    return arr

def quick_sort(arr):
    """
    å¿«é€Ÿæ’åºç®—æ³•
    """
    if len(arr) <= 1:
        return arr
    
    pivot = arr[len(arr) // 2]
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    
    return quick_sort(left) + middle + quick_sort(right)

# æµ‹è¯•
if __name__ == "__main__":
    test_data = [64, 34, 25, 12, 22, 11, 90]
    print(f"åŸæ•°ç»„: {test_data}")
    print(f"å¿«é€Ÿæ’åºç»“æœ: {quick_sort(test_data.copy())}")'''
        
        # é€šç”¨ä»£ç æ¨¡æ¿
        templates = {
            "python": f'''# {prompt}
def solution():
    """
    {prompt}
    
    è¿™æ˜¯ä¸€ä¸ªåŸºç¡€å®ç°æ¨¡æ¿ï¼Œè¯·æ ¹æ®å…·ä½“éœ€æ±‚è¿›è¡Œä¿®æ”¹
    """
    print("Hello, YouCreator.AI!")
    
    # TODO: åœ¨è¿™é‡Œå®ç°å…·ä½“åŠŸèƒ½
    result = "åŠŸèƒ½å®ç°å®Œæˆ"
    
    return result

def main():
    """
    ä¸»å‡½æ•°ï¼Œç”¨äºæµ‹è¯•å’Œæ¼”ç¤º
    """
    try:
        result = solution()
        print(f"æ‰§è¡Œç»“æœ: {{result}}")
    except Exception as e:
        print(f"æ‰§è¡Œå‡ºé”™: {{e}}")

if __name__ == "__main__":
    main()''',
            
            "javascript": f'''// {prompt}
function solution() {{
    /**
     * {prompt}
     * 
     * è¿™æ˜¯ä¸€ä¸ªåŸºç¡€å®ç°æ¨¡æ¿ï¼Œè¯·æ ¹æ®å…·ä½“éœ€æ±‚è¿›è¡Œä¿®æ”¹
     */
    console.log("Hello, YouCreator.AI!");
    
    // TODO: åœ¨è¿™é‡Œå®ç°å…·ä½“åŠŸèƒ½
    const result = "åŠŸèƒ½å®ç°å®Œæˆ";
    
    return result;
}}

function main() {{
    /**
     * ä¸»å‡½æ•°ï¼Œç”¨äºæµ‹è¯•å’Œæ¼”ç¤º
     */
    try {{
        const result = solution();
        console.log(`æ‰§è¡Œç»“æœ: ${{result}}`);
    }} catch (error) {{
        console.error(`æ‰§è¡Œå‡ºé”™: ${{error.message}}`);
    }}
}}

// å¦‚æœæ˜¯åœ¨Node.jsç¯å¢ƒä¸­è¿è¡Œ
if (typeof require !== 'undefined' && require.main === module) {{
    main();
}}''',
            
            "go": f'''package main

import (
    "fmt"
    "log"
)

// {prompt}
func solution() string {{
    fmt.Println("Hello, YouCreator.AI!")
    
    // TODO: åœ¨è¿™é‡Œå®ç°å…·ä½“åŠŸèƒ½
    result := "åŠŸèƒ½å®ç°å®Œæˆ"
    
    return result
}}

func main() {{
    defer func() {{
        if r := recover(); r != nil {{
            log.Printf("ç¨‹åºå¼‚å¸¸: %v", r)
        }}
    }}()
    
    result := solution()
    fmt.Printf("æ‰§è¡Œç»“æœ: %s\\n", result)
}}''',
        }
        
        return templates.get(language, f"// {prompt}\n// TODO: å®ç°åŠŸèƒ½")
    
    async def test_connection(self) -> bool:
        """æµ‹è¯•Groqè¿æ¥"""
        if not self.enabled:
            return False
        
        try:
            test_result = await self.generate_text("Hello", max_tokens=10)
            return "Hello" in test_result or len(test_result) > 20
        except:
            return False
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–Groqå®¢æˆ·ç«¯çŠ¶æ€"""
        return {
            "enabled": self.enabled,
            "api_key_configured": bool(self.api_key),
            "api_key_preview": f"{self.api_key[:20]}..." if self.api_key else None,
            "text_model": self.text_model,
            "code_model": self.code_model,
            "base_url": self.base_url,
            "fallback_enabled": True,
            "note": "å¦‚æœGroq APIä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å¢å¼ºçš„å¤‡ç”¨ç”Ÿæˆæ–¹æ¡ˆ"
        }
