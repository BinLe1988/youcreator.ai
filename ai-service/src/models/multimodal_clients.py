"""
å¤šæ¨¡æ€AIæœåŠ¡å®¢æˆ·ç«¯
æ”¯æŒå›¾åƒç”Ÿæˆã€éŸ³ä¹ç”Ÿæˆå’Œæ™ºèƒ½å†…å®¹åŒ¹é…
"""

import os
import httpx
import asyncio
import logging
import base64
import json
from typing import Dict, Any, Optional, List, Union
from dotenv import load_dotenv
import io
from PIL import Image
import random

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

logger = logging.getLogger(__name__)


class ImageGenerationClient:
    """å›¾åƒç”Ÿæˆå®¢æˆ·ç«¯"""
    
    def __init__(self):
        # æ”¯æŒå¤šä¸ªå›¾åƒç”ŸæˆæœåŠ¡
        self.providers = {
            "stability": {
                "api_key": os.getenv("STABILITY_API_KEY"),
                "base_url": "https://api.stability.ai/v1",
                "enabled": bool(os.getenv("STABILITY_API_KEY"))
            },
            "replicate": {
                "api_key": os.getenv("REPLICATE_API_TOKEN"),
                "base_url": "https://api.replicate.com/v1",
                "enabled": bool(os.getenv("REPLICATE_API_TOKEN"))
            },
            "huggingface": {
                "api_key": os.getenv("HUGGINGFACE_TOKEN"),
                "base_url": "https://api-inference.huggingface.co/models",
                "enabled": bool(os.getenv("HUGGINGFACE_TOKEN"))
            }
        }
        
        # å›¾åƒç”Ÿæˆæ¨¡å‹é…ç½®
        self.models = {
            "stability": ["stable-diffusion-v1-6", "stable-diffusion-xl-1024-v1-0"],
            "replicate": ["stability-ai/stable-diffusion", "stability-ai/sdxl"],
            "huggingface": [
                "runwayml/stable-diffusion-v1-5",
                "stabilityai/stable-diffusion-2-1",
                "CompVis/stable-diffusion-v1-4"
            ]
        }
        
        enabled_providers = [name for name, config in self.providers.items() if config["enabled"]]
        logger.info(f"ğŸ¨ å›¾åƒç”Ÿæˆå®¢æˆ·ç«¯åˆå§‹åŒ–ï¼Œå¯ç”¨æä¾›å•†: {enabled_providers}")
    
    async def generate_image_for_text(self, text: str, style: str = "realistic", **kwargs) -> bytes:
        """ä¸ºæ–‡å­—ç”Ÿæˆé…å›¾"""
        # åˆ†ææ–‡æœ¬å†…å®¹ï¼Œç”Ÿæˆåˆé€‚çš„å›¾åƒæç¤º
        image_prompt = self._analyze_text_for_image(text, style)
        
        return await self.generate_image(image_prompt, **kwargs)
    
    def _analyze_text_for_image(self, text: str, style: str) -> str:
        """åˆ†ææ–‡æœ¬å†…å®¹ï¼Œç”Ÿæˆå›¾åƒæç¤º"""
        # å…³é”®è¯æå–å’Œåœºæ™¯åˆ†æ
        keywords = self._extract_keywords(text)
        scene_type = self._determine_scene_type(text)
        mood = self._analyze_mood(text)
        
        # æ„å»ºå›¾åƒæç¤º
        base_prompt = f"{scene_type}, {mood} atmosphere"
        
        if keywords:
            base_prompt += f", featuring {', '.join(keywords[:3])}"
        
        # æ·»åŠ é£æ ¼æè¿°
        style_prompts = {
            "realistic": "photorealistic, high quality, detailed",
            "artistic": "artistic, painterly, beautiful composition",
            "cartoon": "cartoon style, colorful, friendly",
            "abstract": "abstract art, creative, modern",
            "vintage": "vintage style, retro, nostalgic",
            "minimalist": "minimalist, clean, simple"
        }
        
        style_desc = style_prompts.get(style, "high quality, detailed")
        final_prompt = f"{base_prompt}, {style_desc}"
        
        logger.info(f"ğŸ¨ ä¸ºæ–‡æœ¬ç”Ÿæˆå›¾åƒæç¤º: {final_prompt}")
        return final_prompt
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå¯ä»¥ç”¨æ›´å¤æ‚çš„NLPï¼‰
        keywords = []
        
        # å¸¸è§çš„è§†è§‰å…ƒç´ å…³é”®è¯
        visual_keywords = {
            "è‡ªç„¶": ["nature", "landscape", "trees", "mountains"],
            "åŸå¸‚": ["city", "buildings", "urban", "skyline"],
            "äººç‰©": ["person", "people", "character", "portrait"],
            "åŠ¨ç‰©": ["animal", "wildlife", "pet"],
            "ç§‘æŠ€": ["technology", "futuristic", "digital"],
            "è‰ºæœ¯": ["art", "creative", "artistic"],
            "é£Ÿç‰©": ["food", "cooking", "restaurant"],
            "æ—…è¡Œ": ["travel", "journey", "adventure"],
            "å®¶åº­": ["family", "home", "cozy"],
            "å·¥ä½œ": ["office", "business", "professional"]
        }
        
        text_lower = text.lower()
        for chinese_key, english_words in visual_keywords.items():
            if chinese_key in text:
                keywords.extend(english_words[:2])
        
        return keywords[:5]  # é™åˆ¶å…³é”®è¯æ•°é‡
    
    def _determine_scene_type(self, text: str) -> str:
        """ç¡®å®šåœºæ™¯ç±»å‹"""
        scene_indicators = {
            "å®¤å†…": "indoor scene",
            "å®¤å¤–": "outdoor scene", 
            "é£æ™¯": "landscape",
            "åŸå¸‚": "cityscape",
            "è‡ªç„¶": "natural environment",
            "åŠå…¬": "office environment",
            "å®¶": "home interior",
            "è¡—é“": "street scene",
            "å…¬å›­": "park scene",
            "æµ·è¾¹": "beach scene",
            "å±±": "mountain scene",
            "æ£®æ—": "forest scene"
        }
        
        for indicator, scene in scene_indicators.items():
            if indicator in text:
                return scene
        
        return "beautiful scene"
    
    def _analyze_mood(self, text: str) -> str:
        """åˆ†ææƒ…ç»ªæ°›å›´"""
        mood_indicators = {
            "å¿«ä¹": "joyful, bright",
            "æ‚²ä¼¤": "melancholic, soft lighting",
            "æ¿€åŠ¨": "energetic, vibrant",
            "å¹³é™": "peaceful, serene",
            "ç¥ç§˜": "mysterious, dramatic",
            "æµªæ¼«": "romantic, warm",
            "ç§‘å¹»": "futuristic, sci-fi",
            "ææ€–": "dark, ominous",
            "æ¸©é¦¨": "cozy, warm",
            "ä¸“ä¸š": "professional, clean"
        }
        
        for mood_word, description in mood_indicators.items():
            if mood_word in text:
                return description
        
        return "pleasant, well-lit"
    
    async def generate_image(self, prompt: str, **kwargs) -> bytes:
        """ç”Ÿæˆå›¾åƒ"""
        width = kwargs.get("width", 512)
        height = kwargs.get("height", 512)
        
        # æŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒçš„æä¾›å•†
        for provider_name in ["huggingface", "stability", "replicate"]:
            provider = self.providers.get(provider_name)
            if provider and provider["enabled"]:
                try:
                    logger.info(f"ğŸš€ å°è¯• {provider_name} ç”Ÿæˆå›¾åƒ")
                    return await self._generate_with_provider(provider_name, prompt, width, height)
                except Exception as e:
                    logger.warning(f"âš ï¸ {provider_name} å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
                    continue
        
        # å¦‚æœæ‰€æœ‰æä¾›å•†éƒ½å¤±è´¥ï¼Œç”Ÿæˆå ä½ç¬¦å›¾åƒ
        return self._generate_placeholder_image(prompt, width, height)
    
    async def _generate_with_provider(self, provider_name: str, prompt: str, width: int, height: int) -> bytes:
        """ä½¿ç”¨æŒ‡å®šæä¾›å•†ç”Ÿæˆå›¾åƒ"""
        if provider_name == "huggingface":
            return await self._generate_with_huggingface(prompt, width, height)
        elif provider_name == "stability":
            return await self._generate_with_stability(prompt, width, height)
        elif provider_name == "replicate":
            return await self._generate_with_replicate(prompt, width, height)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider_name}")
    
    async def _generate_with_huggingface(self, prompt: str, width: int, height: int) -> bytes:
        """ä½¿ç”¨Hugging Faceç”Ÿæˆå›¾åƒ"""
        provider = self.providers["huggingface"]
        headers = {
            "Authorization": f"Bearer {provider['api_key']}",
            "Content-Type": "application/json"
        }
        
        for model in self.models["huggingface"]:
            try:
                data = {
                    "inputs": prompt,
                    "parameters": {
                        "width": width,
                        "height": height,
                        "num_inference_steps": 20
                    }
                }
                
                async with httpx.AsyncClient(timeout=60.0) as client:
                    response = await client.post(
                        f"{provider['base_url']}/{model}",
                        headers=headers,
                        json=data
                    )
                    
                    if response.status_code == 200:
                        return response.content
                    else:
                        logger.warning(f"HFæ¨¡å‹ {model} è¿”å›: {response.status_code}")
                        continue
                        
            except Exception as e:
                logger.warning(f"HFæ¨¡å‹ {model} å¤±è´¥: {e}")
                continue
        
        raise Exception("æ‰€æœ‰Hugging Faceå›¾åƒæ¨¡å‹éƒ½ä¸å¯ç”¨")
    
    async def _generate_with_stability(self, prompt: str, width: int, height: int) -> bytes:
        """ä½¿ç”¨Stability AIç”Ÿæˆå›¾åƒ"""
        provider = self.providers["stability"]
        headers = {
            "Authorization": f"Bearer {provider['api_key']}",
            "Content-Type": "application/json"
        }
        
        data = {
            "text_prompts": [{"text": prompt}],
            "cfg_scale": 7,
            "height": height,
            "width": width,
            "steps": 20,
            "samples": 1
        }
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                f"{provider['base_url']}/generation/stable-diffusion-v1-6/text-to-image",
                headers=headers,
                json=data
            )
            
            if response.status_code == 200:
                result = response.json()
                image_data = result["artifacts"][0]["base64"]
                return base64.b64decode(image_data)
            else:
                raise Exception(f"Stability APIé”™è¯¯: {response.status_code}")
    
    async def _generate_with_replicate(self, prompt: str, width: int, height: int) -> bytes:
        """ä½¿ç”¨Replicateç”Ÿæˆå›¾åƒ"""
        # Replicateå®ç°ï¼ˆéœ€è¦æ›´å¤æ‚çš„APIè°ƒç”¨ï¼‰
        raise Exception("Replicateå›¾åƒç”Ÿæˆæš‚æœªå®ç°")
    
    def _generate_placeholder_image(self, prompt: str, width: int, height: int) -> bytes:
        """ç”Ÿæˆå ä½ç¬¦å›¾åƒ"""
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„å ä½ç¬¦å›¾åƒ
        img = Image.new('RGB', (width, height), color=(135, 206, 235))  # å¤©è“è‰²èƒŒæ™¯
        
        # å¯ä»¥æ·»åŠ ä¸€äº›ç®€å•çš„å›¾å½¢æˆ–æ–‡å­—
        from PIL import ImageDraw, ImageFont
        draw = ImageDraw.Draw(img)
        
        # æ·»åŠ æ–‡å­—
        try:
            # å°è¯•ä½¿ç”¨ç³»ç»Ÿå­—ä½“
            font = ImageFont.load_default()
        except:
            font = None
        
        text = "AI Generated Image"
        if font:
            bbox = draw.textbbox((0, 0), text, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
            x = (width - text_width) // 2
            y = (height - text_height) // 2
            draw.text((x, y), text, fill=(255, 255, 255), font=font)
        
        # è½¬æ¢ä¸ºbytes
        img_bytes = io.BytesIO()
        img.save(img_bytes, format='PNG')
        return img_bytes.getvalue()


class MusicGenerationClient:
    """éŸ³ä¹ç”Ÿæˆå®¢æˆ·ç«¯"""
    
    def __init__(self):
        # æ”¯æŒå¤šä¸ªéŸ³ä¹ç”ŸæˆæœåŠ¡
        self.providers = {
            "replicate": {
                "api_key": os.getenv("REPLICATE_API_TOKEN"),
                "base_url": "https://api.replicate.com/v1",
                "enabled": bool(os.getenv("REPLICATE_API_TOKEN"))
            },
            "huggingface": {
                "api_key": os.getenv("HUGGINGFACE_TOKEN"),
                "base_url": "https://api-inference.huggingface.co/models",
                "enabled": bool(os.getenv("HUGGINGFACE_TOKEN"))
            }
        }
        
        # éŸ³ä¹é£æ ¼æ¨¡æ¿
        self.style_templates = {
            "è½»æ¾": "upbeat, cheerful, light",
            "æ‚²ä¼¤": "melancholic, slow, emotional",
            "æ¿€åŠ¨": "energetic, fast, exciting",
            "å¹³é™": "calm, peaceful, ambient",
            "æµªæ¼«": "romantic, gentle, warm",
            "ç¥ç§˜": "mysterious, atmospheric, dark",
            "å²è¯—": "epic, orchestral, dramatic",
            "ç”µå­": "electronic, synthesized, modern",
            "å¤å…¸": "classical, orchestral, elegant",
            "çˆµå£«": "jazz, smooth, sophisticated"
        }
        
        enabled_providers = [name for name, config in self.providers.items() if config["enabled"]]
        logger.info(f"ğŸµ éŸ³ä¹ç”Ÿæˆå®¢æˆ·ç«¯åˆå§‹åŒ–ï¼Œå¯ç”¨æä¾›å•†: {enabled_providers}")
    
    async def generate_music_for_text(self, text: str, duration: int = 30, **kwargs) -> bytes:
        """ä¸ºæ–‡å­—ç”Ÿæˆé…ä¹"""
        # åˆ†ææ–‡æœ¬æƒ…æ„Ÿå’Œé£æ ¼
        music_style = self._analyze_text_for_music(text)
        
        return await self.generate_music(music_style, duration, **kwargs)
    
    async def generate_music_for_image(self, image_description: str, duration: int = 30, **kwargs) -> bytes:
        """ä¸ºå›¾ç‰‡ç”Ÿæˆé…ä¹"""
        # åˆ†æå›¾åƒæè¿°ï¼Œç”ŸæˆéŸ³ä¹é£æ ¼
        music_style = self._analyze_image_for_music(image_description)
        
        return await self.generate_music(music_style, duration, **kwargs)
    
    def _analyze_text_for_music(self, text: str) -> str:
        """åˆ†ææ–‡æœ¬ç”ŸæˆéŸ³ä¹é£æ ¼æè¿°"""
        # æƒ…æ„Ÿåˆ†æ
        emotions = self._detect_emotions(text)
        tempo = self._determine_tempo(text)
        genre = self._suggest_genre(text)
        
        style_desc = f"{emotions}, {tempo} tempo, {genre} style"
        logger.info(f"ğŸµ ä¸ºæ–‡æœ¬ç”ŸæˆéŸ³ä¹é£æ ¼: {style_desc}")
        return style_desc
    
    def _analyze_image_for_music(self, image_description: str) -> str:
        """åˆ†æå›¾åƒæè¿°ç”ŸæˆéŸ³ä¹é£æ ¼"""
        # æ ¹æ®å›¾åƒå†…å®¹æ¨æ–­éŸ³ä¹é£æ ¼
        scene_music_map = {
            "nature": "ambient, peaceful, organic sounds",
            "city": "urban, electronic, rhythmic",
            "portrait": "intimate, emotional, personal",
            "landscape": "expansive, atmospheric, cinematic",
            "abstract": "experimental, creative, unique",
            "vintage": "nostalgic, warm, classic"
        }
        
        for scene, music_style in scene_music_map.items():
            if scene in image_description.lower():
                return music_style
        
        return "ambient, pleasant, background music"
    
    def _detect_emotions(self, text: str) -> str:
        """æ£€æµ‹æ–‡æœ¬æƒ…æ„Ÿ"""
        emotion_keywords = {
            "happy": ["å¿«ä¹", "å¼€å¿ƒ", "å…´å¥‹", "æ„‰å¿«", "æ¬¢ä¹"],
            "sad": ["æ‚²ä¼¤", "éš¾è¿‡", "å¿§éƒ", "æ²®ä¸§", "å¤±è½"],
            "calm": ["å¹³é™", "å®‰é™", "å®é™", "æ”¾æ¾", "èˆ’ç¼“"],
            "energetic": ["æ¿€åŠ¨", "æ´»åŠ›", "å……æ»¡", "çƒ­æƒ…", "åŠ¨æ„Ÿ"],
            "romantic": ["æµªæ¼«", "çˆ±æƒ…", "æ¸©æŸ”", "ç”œèœœ", "æƒ…ä¾£"],
            "mysterious": ["ç¥ç§˜", "æœªçŸ¥", "å¥‡æ€ª", "è¯¡å¼‚", "éšç§˜"]
        }
        
        for emotion, keywords in emotion_keywords.items():
            if any(keyword in text for keyword in keywords):
                return emotion
        
        return "neutral"
    
    def _determine_tempo(self, text: str) -> str:
        """ç¡®å®šéŸ³ä¹èŠ‚æ‹"""
        fast_indicators = ["å¿«", "æ€¥", "è·‘", "é£", "å†²", "æ¿€åŠ¨", "å…´å¥‹"]
        slow_indicators = ["æ…¢", "ç¼“", "é™", "å¹³", "è½»", "æŸ”", "æ‚²"]
        
        if any(indicator in text for indicator in fast_indicators):
            return "fast"
        elif any(indicator in text for indicator in slow_indicators):
            return "slow"
        else:
            return "medium"
    
    def _suggest_genre(self, text: str) -> str:
        """å»ºè®®éŸ³ä¹ç±»å‹"""
        genre_keywords = {
            "classical": ["å¤å…¸", "ä¼˜é›…", "æ­£å¼", "ä¼ ç»Ÿ"],
            "electronic": ["ç§‘æŠ€", "æœªæ¥", "ç°ä»£", "æ•°å­—"],
            "jazz": ["çˆµå£«", "å’–å•¡", "å¤œæ™š", "é…’å§"],
            "ambient": ["ç¯å¢ƒ", "èƒŒæ™¯", "æ°›å›´", "ç©ºé—´"],
            "orchestral": ["å²è¯—", "å®å¤§", "ç”µå½±", "äº¤å“"]
        }
        
        for genre, keywords in genre_keywords.items():
            if any(keyword in text for keyword in keywords):
                return genre
        
        return "ambient"
    
    async def generate_music(self, style_description: str, duration: int = 30, **kwargs) -> bytes:
        """ç”ŸæˆéŸ³ä¹"""
        # å°è¯•ä¸åŒçš„æä¾›å•†
        for provider_name in ["replicate", "huggingface"]:
            provider = self.providers.get(provider_name)
            if provider and provider["enabled"]:
                try:
                    logger.info(f"ğŸš€ å°è¯• {provider_name} ç”ŸæˆéŸ³ä¹")
                    return await self._generate_with_provider(provider_name, style_description, duration)
                except Exception as e:
                    logger.warning(f"âš ï¸ {provider_name} éŸ³ä¹ç”Ÿæˆå¤±è´¥: {e}")
                    continue
        
        # å¦‚æœæ‰€æœ‰æä¾›å•†éƒ½å¤±è´¥ï¼Œç”Ÿæˆå ä½ç¬¦éŸ³é¢‘
        return self._generate_placeholder_audio(style_description, duration)
    
    async def _generate_with_provider(self, provider_name: str, style: str, duration: int) -> bytes:
        """ä½¿ç”¨æŒ‡å®šæä¾›å•†ç”ŸæˆéŸ³ä¹"""
        if provider_name == "replicate":
            return await self._generate_with_replicate(style, duration)
        elif provider_name == "huggingface":
            return await self._generate_with_huggingface(style, duration)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider_name}")
    
    async def _generate_with_replicate(self, style: str, duration: int) -> bytes:
        """ä½¿ç”¨Replicateç”ŸæˆéŸ³ä¹"""
        provider = self.providers["replicate"]
        headers = {
            "Authorization": f"Token {provider['api_key']}",
            "Content-Type": "application/json"
        }
        
        # MusicGenæ¨¡å‹
        data = {
            "version": "b05b1dff1d8c6dc63d14b0cdb42135378dcb87f6373b0d3d341ede46e59e2dab",
            "input": {
                "prompt": style,
                "duration": duration,
                "temperature": 1,
                "top_k": 250,
                "top_p": 0,
                "seed": random.randint(1, 1000000)
            }
        }
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            # åˆ›å»ºé¢„æµ‹
            response = await client.post(
                f"{provider['base_url']}/predictions",
                headers=headers,
                json=data
            )
            
            if response.status_code == 201:
                prediction = response.json()
                prediction_id = prediction["id"]
                
                # è½®è¯¢ç»“æœ
                for _ in range(30):  # æœ€å¤šç­‰å¾…30æ¬¡
                    await asyncio.sleep(2)
                    
                    status_response = await client.get(
                        f"{provider['base_url']}/predictions/{prediction_id}",
                        headers=headers
                    )
                    
                    if status_response.status_code == 200:
                        result = status_response.json()
                        if result["status"] == "succeeded":
                            audio_url = result["output"]
                            # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
                            audio_response = await client.get(audio_url)
                            return audio_response.content
                        elif result["status"] == "failed":
                            raise Exception("éŸ³ä¹ç”Ÿæˆå¤±è´¥")
                
                raise Exception("éŸ³ä¹ç”Ÿæˆè¶…æ—¶")
            else:
                raise Exception(f"Replicate APIé”™è¯¯: {response.status_code}")
    
    async def _generate_with_huggingface(self, style: str, duration: int) -> bytes:
        """ä½¿ç”¨Hugging Faceç”ŸæˆéŸ³ä¹"""
        # Hugging FaceéŸ³ä¹ç”Ÿæˆå®ç°
        raise Exception("Hugging FaceéŸ³ä¹ç”Ÿæˆæš‚æœªå®ç°")
    
    def _generate_placeholder_audio(self, style: str, duration: int) -> bytes:
        """ç”Ÿæˆå ä½ç¬¦éŸ³é¢‘"""
        # ç”Ÿæˆä¸€ä¸ªç®€å•çš„éŸ³é¢‘å ä½ç¬¦ï¼ˆé™éŸ³æˆ–ç®€å•éŸ³è°ƒï¼‰
        import wave
        import struct
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ­£å¼¦æ³¢éŸ³é¢‘
        sample_rate = 44100
        frequency = 440  # A4éŸ³ç¬¦
        frames = int(duration * sample_rate)
        
        audio_data = []
        for i in range(frames):
            # ç”Ÿæˆæ­£å¼¦æ³¢
            value = int(32767 * 0.1 * (i % (sample_rate // frequency)) / (sample_rate // frequency))
            audio_data.append(struct.pack('<h', value))
        
        # åˆ›å»ºWAVæ–‡ä»¶
        audio_bytes = io.BytesIO()
        with wave.open(audio_bytes, 'wb') as wav_file:
            wav_file.setnchannels(1)  # å•å£°é“
            wav_file.setsampwidth(2)  # 16ä½
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(b''.join(audio_data))
        
        return audio_bytes.getvalue()


class MultimodalContentMatcher:
    """å¤šæ¨¡æ€å†…å®¹åŒ¹é…å™¨"""
    
    def __init__(self):
        self.image_client = ImageGenerationClient()
        self.music_client = MusicGenerationClient()
    
    async def create_complete_content(self, text: str, include_image: bool = True, 
                                    include_music: bool = True, **kwargs) -> Dict[str, Any]:
        """ä¸ºæ–‡æœ¬åˆ›å»ºå®Œæ•´çš„å¤šæ¨¡æ€å†…å®¹"""
        result = {
            "text": text,
            "image": None,
            "music": None,
            "metadata": {
                "style_analysis": self._analyze_content_style(text),
                "generation_time": None
            }
        }
        
        import time
        start_time = time.time()
        
        tasks = []
        
        if include_image:
            image_style = kwargs.get("image_style", "realistic")
            tasks.append(self._generate_image_task(text, image_style, kwargs))
        
        if include_music:
            music_duration = kwargs.get("music_duration", 30)
            tasks.append(self._generate_music_task(text, music_duration, kwargs))
        
        # å¹¶è¡Œç”Ÿæˆå›¾åƒå’ŒéŸ³ä¹
        if tasks:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            task_index = 0
            if include_image:
                if not isinstance(results[task_index], Exception):
                    result["image"] = results[task_index]
                task_index += 1
            
            if include_music:
                if not isinstance(results[task_index], Exception):
                    result["music"] = results[task_index]
        
        result["metadata"]["generation_time"] = time.time() - start_time
        return result
    
    async def _generate_image_task(self, text: str, style: str, kwargs: Dict) -> bytes:
        """å›¾åƒç”Ÿæˆä»»åŠ¡"""
        return await self.image_client.generate_image_for_text(
            text, 
            style=style,
            width=kwargs.get("image_width", 512),
            height=kwargs.get("image_height", 512)
        )
    
    async def _generate_music_task(self, text: str, duration: int, kwargs: Dict) -> bytes:
        """éŸ³ä¹ç”Ÿæˆä»»åŠ¡"""
        return await self.music_client.generate_music_for_text(text, duration=duration)
    
    def _analyze_content_style(self, text: str) -> Dict[str, str]:
        """åˆ†æå†…å®¹é£æ ¼"""
        return {
            "mood": self._detect_mood(text),
            "genre": self._detect_genre(text),
            "visual_style": self._suggest_visual_style(text),
            "music_style": self._suggest_music_style(text)
        }
    
    def _detect_mood(self, text: str) -> str:
        """æ£€æµ‹æƒ…ç»ª"""
        mood_indicators = {
            "joyful": ["å¿«ä¹", "å¼€å¿ƒ", "å…´å¥‹", "æ„‰å¿«"],
            "melancholic": ["æ‚²ä¼¤", "éš¾è¿‡", "å¿§éƒ", "æ²®ä¸§"],
            "peaceful": ["å¹³é™", "å®‰é™", "å®é™", "æ”¾æ¾"],
            "energetic": ["æ¿€åŠ¨", "æ´»åŠ›", "å……æ»¡", "çƒ­æƒ…"],
            "romantic": ["æµªæ¼«", "çˆ±æƒ…", "æ¸©æŸ”", "ç”œèœœ"],
            "mysterious": ["ç¥ç§˜", "æœªçŸ¥", "å¥‡æ€ª", "è¯¡å¼‚"]
        }
        
        for mood, keywords in mood_indicators.items():
            if any(keyword in text for keyword in keywords):
                return mood
        
        return "neutral"
    
    def _detect_genre(self, text: str) -> str:
        """æ£€æµ‹ç±»å‹"""
        genre_indicators = {
            "fantasy": ["é­”æ³•", "é¾™", "ç²¾çµ", "é­”å¹»"],
            "sci-fi": ["ç§‘æŠ€", "æœªæ¥", "æœºå™¨äºº", "å¤ªç©º"],
            "romance": ["çˆ±æƒ…", "æµªæ¼«", "æƒ…ä¾£", "çº¦ä¼š"],
            "adventure": ["å†’é™©", "æ¢ç´¢", "æ—…è¡Œ", "å‘ç°"],
            "mystery": ["ç¥ç§˜", "æ‚¬ç–‘", "æ¨ç†", "ç§˜å¯†"],
            "drama": ["æˆå‰§", "æƒ…æ„Ÿ", "äººç”Ÿ", "æ•…äº‹"]
        }
        
        for genre, keywords in genre_indicators.items():
            if any(keyword in text for keyword in keywords):
                return genre
        
        return "general"
    
    def _suggest_visual_style(self, text: str) -> str:
        """å»ºè®®è§†è§‰é£æ ¼"""
        style_map = {
            "realistic": ["çœŸå®", "ç°å®", "ç…§ç‰‡", "çºªå®"],
            "artistic": ["è‰ºæœ¯", "ç»˜ç”»", "åˆ›æ„", "ç¾æœ¯"],
            "cartoon": ["å¡é€š", "åŠ¨ç”»", "å¯çˆ±", "å„¿ç«¥"],
            "vintage": ["å¤å¤", "æ€€æ—§", "ç»å…¸", "è€å¼"],
            "minimalist": ["ç®€çº¦", "ç®€å•", "å¹²å‡€", "ç°ä»£"]
        }
        
        for style, keywords in style_map.items():
            if any(keyword in text for keyword in keywords):
                return style
        
        return "realistic"
    
    def _suggest_music_style(self, text: str) -> str:
        """å»ºè®®éŸ³ä¹é£æ ¼"""
        style_map = {
            "orchestral": ["å²è¯—", "å®å¤§", "ç”µå½±", "äº¤å“"],
            "electronic": ["ç§‘æŠ€", "æœªæ¥", "ç°ä»£", "æ•°å­—"],
            "acoustic": ["è‡ªç„¶", "æ¸©æš–", "äº²å¯†", "åŸå£°"],
            "ambient": ["ç¯å¢ƒ", "èƒŒæ™¯", "æ°›å›´", "ç©ºé—´"],
            "jazz": ["çˆµå£«", "å’–å•¡", "å¤œæ™š", "é…’å§"]
        }
        
        for style, keywords in style_map.items():
            if any(keyword in text for keyword in keywords):
                return style
        
        return "ambient"
