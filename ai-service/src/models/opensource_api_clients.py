"""
å¼€æºAIæœåŠ¡å®¢æˆ·ç«¯é›†åˆ
é›†æˆå¤šä¸ªå…è´¹/å¼€æºçš„AI APIæœåŠ¡
"""

import os
import httpx
import asyncio
import logging
from typing import Dict, Any, Optional, List
from dotenv import load_dotenv
import json

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

logger = logging.getLogger(__name__)


class HuggingFaceClient:
    """Hugging Face Inference APIå®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.api_key = os.getenv("HUGGINGFACE_TOKEN")
        self.base_url = "https://api-inference.huggingface.co/models"
        self.enabled = bool(self.api_key)
        
        # æ¨èçš„å¼€æºæ¨¡å‹
        self.text_models = [
            "microsoft/DialoGPT-large",
            "facebook/blenderbot-400M-distill",
            "microsoft/DialoGPT-medium",
            "google/flan-t5-large"
        ]
        
        self.code_models = [
            "microsoft/CodeGPT-small-py",
            "Salesforce/codegen-350M-mono",
            "microsoft/codebert-base"
        ]
        
        if self.enabled:
            logger.info("âœ… Hugging Faceå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        else:
            logger.warning("âš ï¸ Hugging Face Tokenæœªé…ç½®")
    
    async def generate_text(self, prompt: str, **kwargs) -> str:
        """ä½¿ç”¨Hugging Faceç”Ÿæˆæ–‡æœ¬"""
        if not self.enabled:
            raise ValueError("Hugging Face Tokenæœªé…ç½®")
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        for model in self.text_models:
            try:
                logger.info(f"ğŸš€ å°è¯•HFæ¨¡å‹: {model}")
                
                data = {
                    "inputs": prompt,
                    "parameters": {
                        "max_length": min(kwargs.get("max_tokens", 200), 500),
                        "temperature": kwargs.get("temperature", 0.7),
                        "do_sample": True
                    }
                }
                
                async with httpx.AsyncClient(timeout=30.0) as client:
                    response = await client.post(
                        f"{self.base_url}/{model}",
                        headers=headers,
                        json=data
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        if isinstance(result, list) and len(result) > 0:
                            generated_text = result[0].get("generated_text", "")
                            # æ¸…ç†è¾“å‡ºï¼Œç§»é™¤åŸå§‹æç¤º
                            if prompt in generated_text:
                                generated_text = generated_text.replace(prompt, "").strip()
                            
                            if generated_text:
                                logger.info(f"âœ… HFæ–‡æœ¬ç”ŸæˆæˆåŠŸ ({model})")
                                return generated_text
                    
                    logger.warning(f"âš ï¸ HFæ¨¡å‹ {model} è¿”å›: {response.status_code}")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ HFæ¨¡å‹ {model} å¤±è´¥: {e}")
                continue
        
        raise Exception("æ‰€æœ‰Hugging Faceæ¨¡å‹éƒ½ä¸å¯ç”¨")
    
    async def generate_code(self, prompt: str, **kwargs) -> str:
        """ä½¿ç”¨Hugging Faceç”Ÿæˆä»£ç """
        if not self.enabled:
            raise ValueError("Hugging Face Tokenæœªé…ç½®")
        
        language = kwargs.get("language", "python")
        code_prompt = f"# {prompt}\n# Language: {language}\n"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        for model in self.code_models:
            try:
                logger.info(f"ğŸš€ å°è¯•HFä»£ç æ¨¡å‹: {model}")
                
                data = {
                    "inputs": code_prompt,
                    "parameters": {
                        "max_length": min(kwargs.get("max_tokens", 200), 300),
                        "temperature": 0.2,
                        "do_sample": True
                    }
                }
                
                async with httpx.AsyncClient(timeout=30.0) as client:
                    response = await client.post(
                        f"{self.base_url}/{model}",
                        headers=headers,
                        json=data
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        if isinstance(result, list) and len(result) > 0:
                            generated_code = result[0].get("generated_text", "")
                            # æ¸…ç†è¾“å‡º
                            if code_prompt in generated_code:
                                generated_code = generated_code.replace(code_prompt, "").strip()
                            
                            if generated_code:
                                logger.info(f"âœ… HFä»£ç ç”ŸæˆæˆåŠŸ ({model})")
                                return generated_code
                    
                    logger.warning(f"âš ï¸ HFä»£ç æ¨¡å‹ {model} è¿”å›: {response.status_code}")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ HFä»£ç æ¨¡å‹ {model} å¤±è´¥: {e}")
                continue
        
        raise Exception("æ‰€æœ‰Hugging Faceä»£ç æ¨¡å‹éƒ½ä¸å¯ç”¨")


class OllamaClient:
    """Ollamaæœ¬åœ°AIæœåŠ¡å®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        self.enabled = False
        self.available_models = []
        
        # æ£€æŸ¥Ollamaæ˜¯å¦å¯ç”¨
        asyncio.create_task(self._check_availability())
    
    async def _check_availability(self):
        """æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            async with httpx.AsyncClient(timeout=5.0) as client:
                response = await client.get(f"{self.base_url}/api/tags")
                if response.status_code == 200:
                    result = response.json()
                    self.available_models = [model["name"] for model in result.get("models", [])]
                    self.enabled = len(self.available_models) > 0
                    if self.enabled:
                        logger.info(f"âœ… Ollamaå®¢æˆ·ç«¯å¯ç”¨ï¼Œæ¨¡å‹: {self.available_models}")
                    else:
                        logger.info("âš ï¸ OllamaæœåŠ¡å¯ç”¨ä½†æ— æ¨¡å‹")
        except Exception as e:
            logger.info(f"âš ï¸ OllamaæœåŠ¡ä¸å¯ç”¨: {e}")
    
    async def generate_text(self, prompt: str, **kwargs) -> str:
        """ä½¿ç”¨Ollamaç”Ÿæˆæ–‡æœ¬"""
        if not self.enabled:
            raise ValueError("OllamaæœåŠ¡ä¸å¯ç”¨")
        
        # ä¼˜å…ˆä½¿ç”¨çš„æ¨¡å‹é¡ºåº
        preferred_models = ["llama2", "codellama", "mistral", "phi"]
        models_to_try = [m for m in preferred_models if any(m in model for model in self.available_models)]
        
        if not models_to_try:
            models_to_try = self.available_models[:3]  # ä½¿ç”¨å‰3ä¸ªå¯ç”¨æ¨¡å‹
        
        for model in models_to_try:
            try:
                logger.info(f"ğŸš€ å°è¯•Ollamaæ¨¡å‹: {model}")
                
                data = {
                    "model": model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": kwargs.get("temperature", 0.7),
                        "num_predict": min(kwargs.get("max_tokens", 200), 500)
                    }
                }
                
                async with httpx.AsyncClient(timeout=60.0) as client:
                    response = await client.post(
                        f"{self.base_url}/api/generate",
                        json=data
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        generated_text = result.get("response", "")
                        if generated_text:
                            logger.info(f"âœ… Ollamaæ–‡æœ¬ç”ŸæˆæˆåŠŸ ({model})")
                            return generated_text
                    
                    logger.warning(f"âš ï¸ Ollamaæ¨¡å‹ {model} è¿”å›: {response.status_code}")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ Ollamaæ¨¡å‹ {model} å¤±è´¥: {e}")
                continue
        
        raise Exception("æ‰€æœ‰Ollamaæ¨¡å‹éƒ½ä¸å¯ç”¨")


class OpenRouterClient:
    """OpenRouter APIå®¢æˆ·ç«¯ - æä¾›å¤šç§å¼€æºæ¨¡å‹è®¿é—®"""
    
    def __init__(self):
        self.api_key = os.getenv("OPENROUTER_API_KEY")
        self.base_url = "https://openrouter.ai/api/v1"
        self.enabled = bool(self.api_key)
        
        # å…è´¹/ä¾¿å®œçš„å¼€æºæ¨¡å‹
        self.models = [
            "microsoft/wizardlm-2-8x22b",
            "meta-llama/llama-3-8b-instruct:free",
            "mistralai/mistral-7b-instruct:free",
            "huggingface/CodeBERTa-small-v1"
        ]
        
        if self.enabled:
            logger.info("âœ… OpenRouterå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        else:
            logger.info("âš ï¸ OpenRouter APIå¯†é’¥æœªé…ç½®")
    
    async def generate_text(self, prompt: str, **kwargs) -> str:
        """ä½¿ç”¨OpenRouterç”Ÿæˆæ–‡æœ¬"""
        if not self.enabled:
            raise ValueError("OpenRouter APIå¯†é’¥æœªé…ç½®")
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://youcreator.ai",
            "X-Title": "YouCreator.AI"
        }
        
        for model in self.models:
            try:
                logger.info(f"ğŸš€ å°è¯•OpenRouteræ¨¡å‹: {model}")
                
                data = {
                    "model": model,
                    "messages": [
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "max_tokens": min(kwargs.get("max_tokens", 200), 1000),
                    "temperature": kwargs.get("temperature", 0.7)
                }
                
                async with httpx.AsyncClient(timeout=30.0) as client:
                    response = await client.post(
                        f"{self.base_url}/chat/completions",
                        headers=headers,
                        json=data
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        generated_text = result["choices"][0]["message"]["content"]
                        logger.info(f"âœ… OpenRouteræ–‡æœ¬ç”ŸæˆæˆåŠŸ ({model})")
                        return generated_text
                    
                    logger.warning(f"âš ï¸ OpenRouteræ¨¡å‹ {model} è¿”å›: {response.status_code}")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ OpenRouteræ¨¡å‹ {model} å¤±è´¥: {e}")
                continue
        
        raise Exception("æ‰€æœ‰OpenRouteræ¨¡å‹éƒ½ä¸å¯ç”¨")


class TogetherAIClient:
    """Together AIå®¢æˆ·ç«¯ - å¼€æºæ¨¡å‹æ¨ç†æœåŠ¡"""
    
    def __init__(self):
        self.api_key = os.getenv("TOGETHER_API_KEY")
        self.base_url = "https://api.together.xyz/v1"
        self.enabled = bool(self.api_key)
        
        # Together AIçš„å¼€æºæ¨¡å‹
        self.models = [
            "meta-llama/Llama-2-7b-chat-hf",
            "mistralai/Mistral-7B-Instruct-v0.1",
            "codellama/CodeLlama-7b-Python-hf",
            "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO"
        ]
        
        if self.enabled:
            logger.info("âœ… Together AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        else:
            logger.info("âš ï¸ Together AI APIå¯†é’¥æœªé…ç½®")
    
    async def generate_text(self, prompt: str, **kwargs) -> str:
        """ä½¿ç”¨Together AIç”Ÿæˆæ–‡æœ¬"""
        if not self.enabled:
            raise ValueError("Together AI APIå¯†é’¥æœªé…ç½®")
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        for model in self.models:
            try:
                logger.info(f"ğŸš€ å°è¯•Together AIæ¨¡å‹: {model}")
                
                data = {
                    "model": model,
                    "messages": [
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "max_tokens": min(kwargs.get("max_tokens", 200), 1000),
                    "temperature": kwargs.get("temperature", 0.7)
                }
                
                async with httpx.AsyncClient(timeout=30.0) as client:
                    response = await client.post(
                        f"{self.base_url}/chat/completions",
                        headers=headers,
                        json=data
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        generated_text = result["choices"][0]["message"]["content"]
                        logger.info(f"âœ… Together AIæ–‡æœ¬ç”ŸæˆæˆåŠŸ ({model})")
                        return generated_text
                    
                    logger.warning(f"âš ï¸ Together AIæ¨¡å‹ {model} è¿”å›: {response.status_code}")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ Together AIæ¨¡å‹ {model} å¤±è´¥: {e}")
                continue
        
        raise Exception("æ‰€æœ‰Together AIæ¨¡å‹éƒ½ä¸å¯ç”¨")


class MultiProviderAIClient:
    """å¤šæä¾›å•†AIå®¢æˆ·ç«¯ç®¡ç†å™¨"""
    
    def __init__(self):
        self.providers = {
            "huggingface": HuggingFaceClient(),
            "ollama": OllamaClient(),
            "openrouter": OpenRouterClient(),
            "together": TogetherAIClient()
        }
        
        # ç­‰å¾…Ollamaæ£€æŸ¥å®Œæˆ
        asyncio.create_task(self._initialize_async())
    
    async def _initialize_async(self):
        """å¼‚æ­¥åˆå§‹åŒ–"""
        await asyncio.sleep(1)  # ç­‰å¾…Ollamaæ£€æŸ¥å®Œæˆ
        
        enabled_providers = [name for name, client in self.providers.items() if client.enabled]
        logger.info(f"ğŸ”„ å¯ç”¨çš„AIæä¾›å•†: {enabled_providers}")
    
    async def generate_text(self, prompt: str, **kwargs) -> str:
        """å°è¯•å¤šä¸ªæä¾›å•†ç”Ÿæˆæ–‡æœ¬"""
        # æŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒçš„æä¾›å•†
        provider_order = ["huggingface", "together", "openrouter", "ollama"]
        
        for provider_name in provider_order:
            provider = self.providers.get(provider_name)
            if provider and provider.enabled:
                try:
                    logger.info(f"ğŸš€ å°è¯•æä¾›å•†: {provider_name}")
                    result = await provider.generate_text(prompt, **kwargs)
                    logger.info(f"âœ… {provider_name} æ–‡æœ¬ç”ŸæˆæˆåŠŸ")
                    return result
                except Exception as e:
                    logger.warning(f"âš ï¸ {provider_name} å¤±è´¥: {e}")
                    continue
        
        # å¦‚æœæ‰€æœ‰æä¾›å•†éƒ½å¤±è´¥ï¼Œè¿”å›å¤‡ç”¨å†…å®¹
        return self._generate_fallback_text(prompt, **kwargs)
    
    async def generate_code(self, prompt: str, **kwargs) -> str:
        """å°è¯•å¤šä¸ªæä¾›å•†ç”Ÿæˆä»£ç """
        # ä¼˜å…ˆä½¿ç”¨é€‚åˆä»£ç ç”Ÿæˆçš„æä¾›å•†
        provider_order = ["huggingface", "together", "ollama"]
        
        for provider_name in provider_order:
            provider = self.providers.get(provider_name)
            if provider and provider.enabled and hasattr(provider, 'generate_code'):
                try:
                    logger.info(f"ğŸš€ å°è¯•ä»£ç ç”Ÿæˆæä¾›å•†: {provider_name}")
                    result = await provider.generate_code(prompt, **kwargs)
                    logger.info(f"âœ… {provider_name} ä»£ç ç”ŸæˆæˆåŠŸ")
                    return result
                except Exception as e:
                    logger.warning(f"âš ï¸ {provider_name} ä»£ç ç”Ÿæˆå¤±è´¥: {e}")
                    continue
        
        # å¦‚æœæ‰€æœ‰æä¾›å•†éƒ½å¤±è´¥ï¼Œè¿”å›å¢å¼ºæ¨¡æ¿
        return self._generate_enhanced_code_template(prompt, kwargs.get("language", "python"))
    
    def _generate_fallback_text(self, prompt: str, **kwargs) -> str:
        """å¤‡ç”¨æ–‡æœ¬ç”Ÿæˆ"""
        return f"åŸºäºæç¤ºã€Œ{prompt}ã€çš„AIç”Ÿæˆå†…å®¹ã€‚å½“å‰ä½¿ç”¨å¤šæä¾›å•†å¤‡ç”¨æ–¹æ¡ˆï¼Œç¡®ä¿æœåŠ¡å§‹ç»ˆå¯ç”¨ã€‚åœ¨è¿™ä¸ªå……æ»¡åˆ›æ„çš„æ•°å­—æ—¶ä»£ï¼ŒAIæŠ€æœ¯æ­£åœ¨ä¸ºæ¯ä¸ªäººæä¾›å¼ºå¤§çš„åˆ›ä½œå·¥å…·ï¼Œè®©æƒ³è±¡åŠ›å¾—ä»¥è‡ªç”±å‘æŒ¥ã€‚"
    
    def _generate_enhanced_code_template(self, prompt: str, language: str) -> str:
        """å¢å¼ºçš„ä»£ç æ¨¡æ¿ç”Ÿæˆ"""
        # è¿™é‡Œå¯ä»¥å¤ç”¨ä¹‹å‰çš„ä»£ç æ¨¡æ¿é€»è¾‘
        if "æ–æ³¢é‚£å¥‘" in prompt or "fibonacci" in prompt.lower():
            if language == "python":
                return '''def fibonacci(n):
    """è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬né¡¹"""
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

def fibonacci_optimized(n):
    """ä¼˜åŒ–ç‰ˆæœ¬ - ä½¿ç”¨åŠ¨æ€è§„åˆ’"""
    if n <= 1:
        return n
    
    a, b = 0, 1
    for _ in range(2, n + 1):
        a, b = b, a + b
    return b

# æµ‹è¯•
if __name__ == "__main__":
    for i in range(10):
        print(f"F({i}) = {fibonacci_optimized(i)}")'''
        
        # é€šç”¨æ¨¡æ¿
        templates = {
            "python": f'''# {prompt}
def solution():
    """
    {prompt}
    """
    print("Hello from YouCreator.AI!")
    # TODO: å®ç°å…·ä½“åŠŸèƒ½
    return "å®Œæˆ"

if __name__ == "__main__":
    result = solution()
    print(f"ç»“æœ: {{result}}")''',
            
            "javascript": f'''// {prompt}
function solution() {{
    console.log("Hello from YouCreator.AI!");
    // TODO: å®ç°å…·ä½“åŠŸèƒ½
    return "å®Œæˆ";
}}

console.log(solution());''',
        }
        
        return templates.get(language, f"// {prompt}\n// TODO: å®ç°åŠŸèƒ½")
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰æä¾›å•†çŠ¶æ€"""
        status = {}
        for name, provider in self.providers.items():
            if hasattr(provider, 'get_status'):
                status[name] = provider.get_status()
            else:
                status[name] = {
                    "enabled": provider.enabled,
                    "available": provider.enabled
                }
        return status
