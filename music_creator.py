#!/usr/bin/env python3
"""
YouCreator.AI - éŸ³ä¹åˆ›ä½œå·¥å…·
æ”¯æŒæ–‡å­—ç”ŸæˆéŸ³ä¹ã€å›¾ç‰‡é…ä¹ç­‰åŠŸèƒ½
"""
import requests
import json
import base64
import os
from typing import Dict, List, Optional

class MusicCreator:
    """éŸ³ä¹åˆ›ä½œå™¨"""
    
    def __init__(self, api_base="http://localhost:8000"):
        self.api_base = api_base
        self.session = requests.Session()
        self.music_styles = {
            "ambient": "ç¯å¢ƒéŸ³ä¹ - è½»æ¾èˆ’ç¼“",
            "classical": "å¤å…¸éŸ³ä¹ - ä¼˜é›…åº„é‡", 
            "electronic": "ç”µå­éŸ³ä¹ - ç°ä»£ç§‘æŠ€",
            "jazz": "çˆµå£«éŸ³ä¹ - è‡ªç”±å³å…´",
            "rock": "æ‘‡æ»šéŸ³ä¹ - æ¿€æƒ…æ¾æ¹ƒ",
            "pop": "æµè¡ŒéŸ³ä¹ - æœ—æœ—ä¸Šå£",
            "folk": "æ°‘è°£éŸ³ä¹ - è´¨æœ´è‡ªç„¶",
            "orchestral": "ç®¡å¼¦ä¹ - å®ä¼Ÿå£®ä¸½",
            "piano": "é’¢ç´éŸ³ä¹ - çº¯å‡€ä¼˜ç¾",
            "acoustic": "åŸå£°éŸ³ä¹ - æ¸©æš–çœŸå®",
            "cinematic": "ç”µå½±é…ä¹ - æˆå‰§å¼ åŠ›",
            "meditation": "å†¥æƒ³éŸ³ä¹ - å®é™è‡´è¿œ"
        }
    
    def create_music_from_text(self, 
                              description: str,
                              duration: int = 15,
                              style: str = "ambient",
                              mood: str = "peaceful") -> Dict:
        """æ ¹æ®æ–‡å­—æè¿°åˆ›ä½œéŸ³ä¹"""
        
        # å¢å¼ºéŸ³ä¹æè¿°
        enhanced_description = self._enhance_music_prompt(description, style, mood)
        
        try:
            response = self.session.post(
                f"{self.api_base}/api/v1/bagel/text-to-music",
                json={
                    "text": enhanced_description,
                    "duration": duration,
                    "temperature": 1.0,
                    "top_k": 250,
                    "top_p": 0.0
                },
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get("success"):
                    return {
                        "success": True,
                        "audio_data": result["data"]["audio"],
                        "description": enhanced_description,
                        "original_description": description,
                        "duration": duration,
                        "style": style,
                        "mood": mood,
                        "sample_rate": result["data"].get("sample_rate", 32000)
                    }
                else:
                    return {"success": False, "error": result.get("error", "éŸ³ä¹ç”Ÿæˆå¤±è´¥")}
            else:
                return {"success": False, "error": f"APIè¯·æ±‚å¤±è´¥: {response.status_code}"}
                
        except Exception as e:
            return {"success": False, "error": f"è¯·æ±‚å¼‚å¸¸: {str(e)}"}
    
    def create_music_from_image(self, 
                               image_path: str,
                               duration: int = 15,
                               mood: str = "auto") -> Dict:
        """æ ¹æ®å›¾ç‰‡åˆ›ä½œé…ä¹"""
        
        try:
            # è¯»å–å›¾ç‰‡æ–‡ä»¶
            with open(image_path, 'rb') as f:
                image_data = base64.b64encode(f.read()).decode()
            
            response = self.session.post(
                f"{self.api_base}/api/v1/bagel/image-to-music",
                json={
                    "image_base64": f"data:image/jpeg;base64,{image_data}",
                    "duration": duration,
                    "temperature": 1.0
                },
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get("success"):
                    return {
                        "success": True,
                        "audio_data": result["data"]["audio"],
                        "image_caption": result["data"].get("image_caption", ""),
                        "music_description": result["data"].get("music_description", ""),
                        "duration": duration,
                        "mood": mood,
                        "sample_rate": result["data"].get("sample_rate", 32000)
                    }
                else:
                    return {"success": False, "error": result.get("error", "é…ä¹ç”Ÿæˆå¤±è´¥")}
            else:
                return {"success": False, "error": f"APIè¯·æ±‚å¤±è´¥: {response.status_code}"}
                
        except FileNotFoundError:
            return {"success": False, "error": f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}"}
        except Exception as e:
            return {"success": False, "error": f"è¯·æ±‚å¼‚å¸¸: {str(e)}"}
    
    def create_theme_music(self, theme: str, duration: int = 20) -> Dict:
        """åˆ›ä½œä¸»é¢˜éŸ³ä¹"""
        
        theme_descriptions = {
            "adventure": "å†’é™©ä¸»é¢˜éŸ³ä¹ï¼Œæ¿€åŠ¨äººå¿ƒçš„æ—‹å¾‹ï¼Œå……æ»¡æ¢ç´¢ç²¾ç¥",
            "romance": "æµªæ¼«ä¸»é¢˜éŸ³ä¹ï¼Œæ¸©æŸ”ç”œç¾çš„æ—‹å¾‹ï¼Œè¡¨è¾¾çˆ±æƒ…ç¾å¥½",
            "mystery": "ç¥ç§˜ä¸»é¢˜éŸ³ä¹ï¼Œæ‚¬ç–‘ç´§å¼ çš„æ°›å›´ï¼Œå¼•äººå…¥èƒœ",
            "victory": "èƒœåˆ©ä¸»é¢˜éŸ³ä¹ï¼Œé›„å£®æ¿€æ˜‚çš„æ—‹å¾‹ï¼Œåº†ç¥æˆåŠŸ",
            "sadness": "æ‚²ä¼¤ä¸»é¢˜éŸ³ä¹ï¼Œå¿§éƒæ·±æ²‰çš„æ—‹å¾‹ï¼Œè¡¨è¾¾å“€æ„",
            "hope": "å¸Œæœ›ä¸»é¢˜éŸ³ä¹ï¼Œæ˜äº®å‘ä¸Šçš„æ—‹å¾‹ï¼Œå……æ»¡æ­£èƒ½é‡",
            "nature": "è‡ªç„¶ä¸»é¢˜éŸ³ä¹ï¼Œæ¸…æ–°è‡ªç„¶çš„å£°éŸ³ï¼Œå›å½’æœ¬çœŸ",
            "space": "å¤ªç©ºä¸»é¢˜éŸ³ä¹ï¼Œå®å¤§ç¥ç§˜çš„éŸ³æ•ˆï¼Œæ¢ç´¢å®‡å®™",
            "childhood": "ç«¥å¹´ä¸»é¢˜éŸ³ä¹ï¼Œçº¯çœŸå¿«ä¹çš„æ—‹å¾‹ï¼Œå›å¿†ç¾å¥½",
            "epic": "å²è¯—ä¸»é¢˜éŸ³ä¹ï¼Œå®ä¼Ÿå£®ä¸½çš„ç¼–æ›²ï¼Œæ°”åŠ¿ç£…ç¤´"
        }
        
        description = theme_descriptions.get(theme, f"{theme}ä¸»é¢˜éŸ³ä¹")
        return self.create_music_from_text(description, duration, "orchestral", theme)
    
    def create_ambient_soundscape(self, environment: str, duration: int = 30) -> Dict:
        """åˆ›ä½œç¯å¢ƒéŸ³æ™¯"""
        
        environment_descriptions = {
            "forest": "æ£®æ—ç¯å¢ƒéŸ³æ™¯ï¼Œé¸Ÿé¸£è™«å«ï¼Œæ ‘å¶æ²™æ²™å£°ï¼Œå®é™è‡ªç„¶",
            "ocean": "æµ·æ´‹ç¯å¢ƒéŸ³æ™¯ï¼Œæµ·æµªæ‹å²¸ï¼Œæµ·é¸¥é¸£å«ï¼Œæ¸…æ–°æµ·é£",
            "rain": "é›¨å¤©ç¯å¢ƒéŸ³æ™¯ï¼Œé›¨æ»´å£°ï¼Œé›·å£°ï¼Œæ¹¿æ¶¦æ¸…æ–°çš„æ°›å›´",
            "city": "åŸå¸‚ç¯å¢ƒéŸ³æ™¯ï¼Œè½¦æµå£°ï¼Œäººå£°ï¼Œç°ä»£éƒ½å¸‚çš„èŠ‚å¥",
            "mountain": "å±±åŒºç¯å¢ƒéŸ³æ™¯ï¼Œé£å£°ï¼Œå›å£°ï¼Œç©ºæ—·å®é™çš„æ„Ÿè§‰",
            "cafe": "å’–å•¡å…ç¯å¢ƒéŸ³æ™¯ï¼Œè½»æŸ”èƒŒæ™¯éŸ³ä¹ï¼Œè°ˆè¯å£°ï¼Œæ¸©é¦¨æ°›å›´",
            "library": "å›¾ä¹¦é¦†ç¯å¢ƒéŸ³æ™¯ï¼Œç¿»ä¹¦å£°ï¼Œè„šæ­¥å£°ï¼Œå®‰é™å­¦ä¹ æ°›å›´",
            "fireplace": "å£ç‚‰ç¯å¢ƒéŸ³æ™¯ï¼Œç«ç„°ç‡ƒçƒ§å£°ï¼Œæ¸©æš–èˆ’é€‚çš„æ„Ÿè§‰"
        }
        
        description = environment_descriptions.get(environment, f"{environment}ç¯å¢ƒéŸ³æ™¯")
        return self.create_music_from_text(description, duration, "ambient", "peaceful")
    
    def _enhance_music_prompt(self, description: str, style: str, mood: str) -> str:
        """å¢å¼ºéŸ³ä¹ç”Ÿæˆæç¤ºè¯"""
        
        style_keywords = {
            "ambient": "ambient, atmospheric, ethereal, floating",
            "classical": "classical, orchestral, elegant, refined",
            "electronic": "electronic, synthesized, digital, modern",
            "jazz": "jazz, improvised, swing, sophisticated",
            "rock": "rock, energetic, powerful, driving",
            "pop": "pop, catchy, melodic, accessible",
            "folk": "folk, acoustic, traditional, storytelling",
            "orchestral": "orchestral, symphonic, grand, majestic",
            "piano": "piano, solo, expressive, intimate",
            "acoustic": "acoustic, natural, organic, warm",
            "cinematic": "cinematic, dramatic, emotional, epic",
            "meditation": "meditation, peaceful, calming, spiritual"
        }
        
        mood_keywords = {
            "happy": "joyful, uplifting, bright, cheerful",
            "sad": "melancholic, somber, emotional, touching",
            "peaceful": "calm, serene, tranquil, relaxing",
            "energetic": "dynamic, vibrant, exciting, powerful",
            "mysterious": "mysterious, enigmatic, suspenseful, dark",
            "romantic": "romantic, tender, loving, intimate",
            "epic": "epic, heroic, grand, triumphant",
            "nostalgic": "nostalgic, wistful, reminiscent, bittersweet"
        }
        
        style_desc = style_keywords.get(style, "")
        mood_desc = mood_keywords.get(mood, "")
        
        enhanced = f"{description}"
        if style_desc:
            enhanced += f", {style_desc}"
        if mood_desc:
            enhanced += f", {mood_desc}"
        
        return enhanced
    
    def save_music(self, audio_data: str, filename: str, metadata: Dict = None):
        """ä¿å­˜éŸ³ä¹æ–‡ä»¶"""
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = "music_creations"
            os.makedirs(output_dir, exist_ok=True)
            
            # è§£ç éŸ³é¢‘æ•°æ®
            if audio_data.startswith('data:audio'):
                audio_data = audio_data.split(',')[1]
            
            audio_bytes = base64.b64decode(audio_data)
            
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            filepath = os.path.join(output_dir, filename)
            with open(filepath, 'wb') as f:
                f.write(audio_bytes)
            
            # ä¿å­˜å…ƒæ•°æ®
            if metadata:
                metadata_file = filepath.replace('.wav', '_metadata.json')
                with open(metadata_file, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… éŸ³ä¹å·²ä¿å­˜åˆ°: {filepath}")
            return filepath
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return None

def interactive_mode():
    """äº¤äº’å¼éŸ³ä¹åˆ›ä½œæ¨¡å¼"""
    creator = MusicCreator()
    
    print("ğŸµ YouCreator.AI éŸ³ä¹åˆ›ä½œå·¥å…·")
    print("=" * 50)
    
    while True:
        print("\nğŸ¼ è¯·é€‰æ‹©åˆ›ä½œç±»å‹:")
        print("1. æ–‡å­—ç”ŸæˆéŸ³ä¹")
        print("2. å›¾ç‰‡é…ä¹")
        print("3. ä¸»é¢˜éŸ³ä¹")
        print("4. ç¯å¢ƒéŸ³æ™¯")
        print("5. æŸ¥çœ‹éŸ³ä¹é£æ ¼")
        print("0. é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-5): ").strip()
        
        if choice == "0":
            print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨YouCreator.AI!")
            break
        elif choice == "1":
            text_to_music(creator)
        elif choice == "2":
            image_to_music(creator)
        elif choice == "3":
            theme_music(creator)
        elif choice == "4":
            ambient_soundscape(creator)
        elif choice == "5":
            show_music_styles(creator)
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

def text_to_music(creator):
    """æ–‡å­—ç”ŸæˆéŸ³ä¹"""
    print("\nğŸ¤ æ–‡å­—ç”ŸæˆéŸ³ä¹")
    print("-" * 30)
    
    description = input("è¯·æè¿°æ‚¨æƒ³è¦çš„éŸ³ä¹: ").strip()
    if not description:
        print("âŒ éŸ³ä¹æè¿°ä¸èƒ½ä¸ºç©º")
        return
    
    # é€‰æ‹©é£æ ¼
    styles = list(creator.music_styles.items())
    print("\nè¯·é€‰æ‹©éŸ³ä¹é£æ ¼:")
    for i, (key, desc) in enumerate(styles[:6], 1):
        print(f"{i}. {desc}")
    print("7. æ›´å¤šé£æ ¼...")
    
    style_choice = input("è¯·é€‰æ‹© (1-7): ").strip()
    
    if style_choice == "7":
        for i, (key, desc) in enumerate(styles[6:], 8):
            print(f"{i}. {desc}")
        style_choice = input("è¯·é€‰æ‹© (8-12): ").strip()
    
    style_idx = int(style_choice) - 1 if style_choice.isdigit() else 0
    style_key = styles[style_idx][0] if 0 <= style_idx < len(styles) else "ambient"
    
    # é€‰æ‹©æƒ…ç»ª
    moods = ["peaceful", "happy", "sad", "energetic", "mysterious", "romantic"]
    print("\nè¯·é€‰æ‹©éŸ³ä¹æƒ…ç»ª:")
    for i, mood in enumerate(moods, 1):
        print(f"{i}. {mood}")
    
    mood_choice = input("è¯·é€‰æ‹© (1-6): ").strip()
    mood = moods[int(mood_choice)-1] if mood_choice.isdigit() and 1 <= int(mood_choice) <= 6 else "peaceful"
    
    # é€‰æ‹©æ—¶é•¿
    duration = input("è¯·è¾“å…¥éŸ³ä¹æ—¶é•¿(ç§’) [15]: ").strip()
    duration = int(duration) if duration.isdigit() and 5 <= int(duration) <= 30 else 15
    
    print(f"\nğŸ¯ å¼€å§‹åˆ›ä½œéŸ³ä¹...")
    print(f"   æè¿°: {description}")
    print(f"   é£æ ¼: {creator.music_styles[style_key]}")
    print(f"   æƒ…ç»ª: {mood}")
    print(f"   æ—¶é•¿: {duration}ç§’")
    
    result = creator.create_music_from_text(description, duration, style_key, mood)
    
    if result["success"]:
        print("\nâœ… éŸ³ä¹åˆ›ä½œå®Œæˆ!")
        
        # ä¿å­˜éŸ³ä¹
        timestamp = __import__('datetime').datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"music_{style_key}_{timestamp}.wav"
        
        metadata = {
            "description": description,
            "style": creator.music_styles[style_key],
            "mood": mood,
            "duration": duration,
            "created_at": timestamp
        }
        
        creator.save_music(result["audio_data"], filename, metadata)
    else:
        print(f"âŒ åˆ›ä½œå¤±è´¥: {result['error']}")

def image_to_music(creator):
    """å›¾ç‰‡é…ä¹"""
    print("\nğŸ–¼ï¸  å›¾ç‰‡é…ä¹")
    print("-" * 30)
    
    image_path = input("è¯·è¾“å…¥å›¾ç‰‡æ–‡ä»¶è·¯å¾„: ").strip()
    if not image_path:
        print("âŒ å›¾ç‰‡è·¯å¾„ä¸èƒ½ä¸ºç©º")
        return
    
    if not os.path.exists(image_path):
        print("âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    duration = input("è¯·è¾“å…¥éŸ³ä¹æ—¶é•¿(ç§’) [15]: ").strip()
    duration = int(duration) if duration.isdigit() and 5 <= int(duration) <= 30 else 15
    
    print(f"\nğŸ¯ å¼€å§‹ä¸ºå›¾ç‰‡åˆ›ä½œé…ä¹...")
    print(f"   å›¾ç‰‡: {image_path}")
    print(f"   æ—¶é•¿: {duration}ç§’")
    
    result = creator.create_music_from_image(image_path, duration)
    
    if result["success"]:
        print("\nâœ… é…ä¹åˆ›ä½œå®Œæˆ!")
        print(f"   å›¾ç‰‡æè¿°: {result.get('image_caption', 'N/A')}")
        print(f"   éŸ³ä¹æè¿°: {result.get('music_description', 'N/A')}")
        
        # ä¿å­˜éŸ³ä¹
        timestamp = __import__('datetime').datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"soundtrack_{timestamp}.wav"
        
        metadata = {
            "type": "image_soundtrack",
            "image_path": image_path,
            "image_caption": result.get('image_caption', ''),
            "music_description": result.get('music_description', ''),
            "duration": duration,
            "created_at": timestamp
        }
        
        creator.save_music(result["audio_data"], filename, metadata)
    else:
        print(f"âŒ é…ä¹å¤±è´¥: {result['error']}")

def theme_music(creator):
    """ä¸»é¢˜éŸ³ä¹åˆ›ä½œ"""
    print("\nğŸ­ ä¸»é¢˜éŸ³ä¹åˆ›ä½œ")
    print("-" * 30)
    
    themes = [
        "adventure", "romance", "mystery", "victory", "sadness",
        "hope", "nature", "space", "childhood", "epic"
    ]
    
    print("è¯·é€‰æ‹©éŸ³ä¹ä¸»é¢˜:")
    for i, theme in enumerate(themes, 1):
        print(f"{i:2d}. {theme}")
    
    theme_choice = input("è¯·é€‰æ‹© (1-10): ").strip()
    theme = themes[int(theme_choice)-1] if theme_choice.isdigit() and 1 <= int(theme_choice) <= 10 else "adventure"
    
    duration = input("è¯·è¾“å…¥éŸ³ä¹æ—¶é•¿(ç§’) [20]: ").strip()
    duration = int(duration) if duration.isdigit() and 5 <= int(duration) <= 30 else 20
    
    print(f"\nğŸ¯ å¼€å§‹åˆ›ä½œ{theme}ä¸»é¢˜éŸ³ä¹...")
    
    result = creator.create_theme_music(theme, duration)
    
    if result["success"]:
        print("\nâœ… ä¸»é¢˜éŸ³ä¹åˆ›ä½œå®Œæˆ!")
        
        # ä¿å­˜éŸ³ä¹
        timestamp = __import__('datetime').datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"theme_{theme}_{timestamp}.wav"
        
        metadata = {
            "type": "theme_music",
            "theme": theme,
            "duration": duration,
            "created_at": timestamp
        }
        
        creator.save_music(result["audio_data"], filename, metadata)
    else:
        print(f"âŒ åˆ›ä½œå¤±è´¥: {result['error']}")

def ambient_soundscape(creator):
    """ç¯å¢ƒéŸ³æ™¯åˆ›ä½œ"""
    print("\nğŸŒ¿ ç¯å¢ƒéŸ³æ™¯åˆ›ä½œ")
    print("-" * 30)
    
    environments = [
        "forest", "ocean", "rain", "city", 
        "mountain", "cafe", "library", "fireplace"
    ]
    
    print("è¯·é€‰æ‹©ç¯å¢ƒç±»å‹:")
    for i, env in enumerate(environments, 1):
        print(f"{i}. {env}")
    
    env_choice = input("è¯·é€‰æ‹© (1-8): ").strip()
    environment = environments[int(env_choice)-1] if env_choice.isdigit() and 1 <= int(env_choice) <= 8 else "forest"
    
    duration = input("è¯·è¾“å…¥éŸ³æ™¯æ—¶é•¿(ç§’) [30]: ").strip()
    duration = int(duration) if duration.isdigit() and 10 <= int(duration) <= 60 else 30
    
    print(f"\nğŸ¯ å¼€å§‹åˆ›ä½œ{environment}ç¯å¢ƒéŸ³æ™¯...")
    
    result = creator.create_ambient_soundscape(environment, duration)
    
    if result["success"]:
        print("\nâœ… ç¯å¢ƒéŸ³æ™¯åˆ›ä½œå®Œæˆ!")
        
        # ä¿å­˜éŸ³ä¹
        timestamp = __import__('datetime').datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"ambient_{environment}_{timestamp}.wav"
        
        metadata = {
            "type": "ambient_soundscape",
            "environment": environment,
            "duration": duration,
            "created_at": timestamp
        }
        
        creator.save_music(result["audio_data"], filename, metadata)
    else:
        print(f"âŒ åˆ›ä½œå¤±è´¥: {result['error']}")

def show_music_styles(creator):
    """æ˜¾ç¤ºæ‰€æœ‰éŸ³ä¹é£æ ¼"""
    print("\nğŸ¼ å¯ç”¨éŸ³ä¹é£æ ¼")
    print("-" * 30)
    
    for key, desc in creator.music_styles.items():
        print(f"â€¢ {desc}")
    
    input("\næŒ‰å›è½¦é”®ç»§ç»­...")

def main():
    """ä¸»å‡½æ•°"""
    interactive_mode()

if __name__ == "__main__":
    main()
